[
["index.html", "Best Practices for Using eBird Data Welcome", " Best Practices for Using eBird Data Matthew Strimas-Mackey, Alison Johnston, Wesley M. Hochachka, Viviana Ruiz-Gutierrez, Orin J. Robinson, Eliot T. Miller, Tom Auer, Steve Kelling, Daniel Fink 2019-03-19 Welcome This book is currently under active development. Please explore and give us feedback, but be aware that some sections are incomplete and others may still contain bugs. Best Practices for Using eBird Data is a supplement to Best practices for making reliable inferences from citizen science data: case study using eBird to estimate species distributions (Johnston et al. 2019). This paper describes the challenges associated with making inferences from biological citizen science data and proposes a set of best practices for making reliable estimates of species distributions from these data. Throughout, the paper uses eBird, the world’s largest biological citizen science project, as a case study to illustrate the good practices. This book acts as a supplement to the paper, showing readers how to implement these best practices within R using real data from eBird. After completing this book, readers should be able to extract data from the eBird database suitable for their own studies, process these data to prepare them for robust analyses, collect environmental covariates for modeling, and fit and assess models estimating encounter rate, occupancy, and relative abundance. Readers should be comfortable with the R programming language, and read the Prerequisites and Setup sections of the introduction, before diving into this book. A preprint of the paper associated with this book is currently available on bioRxiv. This book is a living document that will be regularly updated. To submit fixes or suggest additions and improvements to the book, please file an issue on GitHub. "],
["intro.html", "Chapter 1 Introduction and Setup 1.1 Introduction 1.2 Prerequisites 1.3 Setup", " Chapter 1 Introduction and Setup 1.1 Introduction Citizen science data are increasingly making important contributions to ecological research and conservation. One of the most common forms of citizen science data is derived from members of the public recording species observations. eBird (Sullivan et al. 2014) is the largest of these biological citizen science programs. As of January 2019, the database contained nearly 600 million bird observations from every country in the world, with observations of nearly every bird species on Earth. The eBird database is valuable to researchers across the globe, due to its year-round, broad spatial coverage, high volumes of open access data, and applications to many ecological questions. These data have been widely used in scientific research to study phenology, species distributions, population trends, evolution, behavior, global change, and conservation. However, robust inference with eBird data requires careful processing of the data to address the challenges associated with citizen science datasets. This book, and the associated paper, outlines a set of best practices for addressing these challenges and making reliable estimates of species distributions from eBird data. There are two key aspects that distinguish eBird from many other citizen science projects and facilitate robust ecological analyses: the checklist structure enables non-detection to be inferred and the effort information associated with a checklist facilitates robust analyses by accounting for variation in the observation process (La Sorte et al. 2018; Kelling et al. 2018). When a participant submits data to eBird, sightings of multiple species from the same observation period are grouped together into a single checklist. Complete checklists are those for which the participant reported all birds that they were able to detect and identify. Critically, this enables scientists to infer counts of zero individuals for the species that were not reported. If checklists are not complete, it’s not possible to ascertain whether the absence of a species on a list was a non-detection or the result of a participant not recording the species. In addition, citizen science projects occur on a spectrum from those with predefined sampling structures that resemble more traditional survey designs, to those that are unstructured and collect observations opportunistically. eBird is a semi-structured project, having flexible, easy to follow protocols that attract many participants, but also collecting data on the observation process (e.g. amount of time spent birding, number of observers, etc.), which can be used in subsequent analyses (Kelling et al. 2018). Despite the strengths of eBird data, species observations collected through citizen science projects present a number of challenges that are not found in conventional scientific data. The following are some of the primary challenges associated these data; challenges that will be addressed throughout this book: Taxonomic bias: participants often have preferences for certain species, which may lead to preferential recording of some species over others (Greenwood 2007; Tulloch and Szabo 2012). Restricting analyses to complete checklists largely mitigates this issue. Spatial bias: most participants in citizen science surveys sample near their homes (Luck et al. 2004), in easily accessible areas such as roadsides (Kadmon, Farber, and Danin 2004), or in areas and habitats of known high biodiversity (Prendergast et al. 1993). A simple method to reduce the spatial bias is to create an equal area grid over the region of interest, and sample a given number of checklists from within each grid cell. Temporal bias: participants preferentially sample when they are available, such as weekends (Courter et al. 2013), and at times of year when they expect to observe more birds, notably during spring migration (Sullivan et al. 2014). To address the weekend bias, we recommend using a temporal scale of a week or multiple weeks for most analyses. Spatial precision: the spatial location of an eBird checklist is given as a single latitude-longitude point; however, this may not be precise for two main reasons. First, for traveling checklists, this location represents just one point on the journey. Second, eBird checklists are often assigned to a hotspot (a common location for all birders visiting a popular birding site) rather than their true location. For these reasons, it’s not appropriate to align the eBird locations with very precise habitat covariates, and we recommend summarizing covariates within a neighborhood around the checklist location. Class imbalance: bird species that are rare or hard to detect may have data with high class imbalance, with many more checklists with non-detections than detections. For these species, a distribution model predicting that the species is absent everywhere will have high accuracy, but no ecological value. We’ll follow the methods for addressing class imbalance proposed by Robinson et al. (2018). Observer variation: eBird data are collected from participants with a wide variety of behavior, experience, and skill in detecting and identifying species (Kelling et al. 2015). To address this, each checklist is assigned a Checklist Calibration Index (CCI), which calibrates observers and checklists against others from similar times and places and accounts for variation in observer behavior, equipment, and skill at detecting species (Johnston et al. 2018). Kelling et al. (2015)] Variation in detectability: detectability describes the probability of a species that is present in an area being detected and identified. It varies by season, habitat, and species (Johnston et al. 2014, 2018). Furthermore, eBird data are collected with high variation in effort, time of day, number of observers, and external conditions such as weather, all of which can affect the detectability of species (Ellis and Taylor 2018; Oliveira et al. 2018). Therefore, detectability is particularly important to consider when inference is compared between seasons, habitats or species. Since eBird uses a semi-structured protocol, that collects variables associated with variation in detectability, we’ll be able to account for a larger proportion of this variation in our analyses. The remainder of this book will demonstrate how to address these challenges using real data from eBird to produce reliable estimates of species distributions. In general, we’ll take a two-pronged approach to dealing with unstructured data and maximizing the value of citizen science data: imposing more structure onto the data via data filtering and including covariates in models to account for the variation. The next two chapters show how to access and prepare eBird data and habitat covariates, respectively. The remaining three chapters provide examples of different species distribution models that can be fit using these data: encounter rate models, occupancy models, and abundance models. Although these examples focus on the use of eBird data, in many cases they also apply to similar citizen science datasets. 1.2 Prerequisites To understand the code examples used throughout this book, some knowledge of the programming language R is required. If you don’t meet this requirement, or begin to feel lost trying to understand the code used in this book, we suggest consulting one of the excellent free resources available online for learning R. For those with little or no prior programming experience, Hands-On Programming with R is an excellent introduction. For those with some familiarity with the basics of R that want to take their skills to the next level, we suggest R for Data Science as the best resource for learning how to work with data within R. 1.3 Setup 1.3.1 Data package The first two chapters of this book focus on obtaining and preparing eBird and habitat data for the modeling that will occur in the remaining chapters. These steps can be time consuming and laborious. If you’d like to skip straight to the analysis, download this package of prepared data. Unzip this file so that the contents are in the data/ subdirectory of your RStudio project folder. This will allow you to jump right in to the modeling and ensure that you’re using exactly the same data as was used when creating this book. 1.3.2 Getting eBird data access The complete eBird database is provided via the eBird Basic Dataset (EBD), a large tab-separated text file. To access the EBD, begin by creating an eBird account and signing in. Then visit the eBird Data Access page and fill out the data access request form. eBird data access is free; however, you will need to request access in order to download the EBD. Filling out the access request form allows eBird to keep track of the number of people using the data and obtain information on the applications for which the data are used. Once you have access to the data, proceed to the download page. Download both the World EBD (~ 42 GB compressed, ~ 210 GB uncompressed) and corresponding Sampling Event Data (~ 3.5 GB compressed, ~ 11 GB uncompressed). The former provides observation-level data, while the latter provides checklist-level data; both files are required for species distribution modeling. The files will be in .tar format, and should be unarchived. The resulting directories will contain files with extension .txt.gz, these files should be uncompressed (on Windows use 7-Zip, on Mac use the default system uncompression utility) to produce two text files (e.g., ebd_relDec-2018.txt and ebd_sampling_relDec-2018.txt). Move these files to a sensible, central location on your computer. If the files are too large to fit on your computer’s hard drive, they can be stored on an external hard drive. Each time you want to access eBird data in an R project, you’ll need to reference the full path to these text files, for example ~/data/ebird/ebd_relJan-2019.txt. In general, it’s best to avoid using absolute paths in R scripts because it makes them less portable–if you’re sharing the files with someone else, they’ll need to change the file paths to point to the location at which they’ve stored the eBird data. The R package auk provides a workaround for this, by allowing users to set an environment variable (EDB_PATH) that points to the directory where you’ve stored the eBird data. To set this variable, use the function auk_set_ebd_path(). For example, if the EBD and Sampling Event Data files are in ~/data/ebird/, use: # install or update auk install.packages(&quot;auk&quot;) # set ebd path auk::auk_set_ebd_path(&quot;~/data/ebird/&quot;) After restarting your R session, you should be able to refer directly to the EBD or Sampling Event Data files (e.g., auk_ebd(&quot;ebd_relAug-2018.txt&quot;)). Provided your collaborators have also set EDB_PATH, your scripts should now be portable. You now have access to the full eBird dataset! Note, however, that the EBD is updated monthly. If you want the most recent eBird records, be sure to regularly download an updated version. Finally, whenever you update the EBD, always update the auk package as well, this will ensure that auk will be able to handle any changes to the EBD that may have occurred. 1.3.3 Software The examples throughout this website use the programming language R (R Core Team 2018) to work with eBird data. If you don’t have R installed, download it now, if you already have R, chances are you’re using an outdated version, so update it to the latest version now. R is updated regularly, and it is important that you have the most recent version of R to avoid headaches when installing packages. We suggest checking every couple months to see if a new version has been released. We strongly encourage R users to use RStudio. RStudio is not required to follow along with this book; however, it will make your R experience significantly better. If you don’t have RStudio, download it now, if you already have it, update it because new versions with useful additional features are regularly released. Pro tip: immediately go into RStudio preferences and on the General pane uncheck “Restore .RData into workspace at startup” and set “Save workspace to .RData on exit” to “Never”. This will avoid cluttering your R session with old data and save you headaches down the road. Due to the massive size of the eBird dataset, working with it requires the Unix command-line utility AWK. You won’t need to use AWK directly, as the R package auk does this hard work for you, but you do need AWK to be installed on your computer. Linux and Mac users should already have AWK installed on their machines; however, Windows user will need to install Cygwin to gain access to AWK. Cygwin is free software that allows Windows users to use Unix tools. Cygwin should be installed in the default location (C:/cygwin/bin/gawk.exe or C:/cygwin64/bin/gawk.exe) in order for everything to work correctly. 1.3.4 R packages The examples in this book use a variety of R packages for accessing eBird data, working with spatial data, data processing and manipulation, and model fitting. To install all the packages necessary to work through this book, run the following code: install.packages(&quot;remotes&quot;) remotes::install_github(&quot;mstrimas/ebppackages&quot;) Note that several of the spatial packages require dependencies. If installing these packages fails, consult the instructions for installing dependencies on the sf package website. Finally, ensure all R packages are updated to the most recent by clicking on the Update button on the Packages tab in RStudio. 1.3.5 Tidyverse Throughout this book, we use packages from the Tidyverse, an opinionated collection of R packages designed for data science. Packages such as ggplot2, for data visualization, and dplyr, for data manipulation, are two of the most well known Tidyverse packages; however, there are many more. In the following chapters, we often use Tidyverse functions without explanation. If you encounter a function you’re unfamiliar with, consult the documentation for help (e.g. ?mutate to see help for the dplyr function mutate()). More generally, the free online book R for Data Science by Hadley Wickham is the best introduction to working with data in R using the Tidyverse. The one piece of the Tidyverse that we will cover here, because it is ubiquitous throughout this book and unfamiliar to many, is the pipe operator %&gt;%. The pipe operator takes the expression to the left of it and “pipes” it into the first argument of the expression on the right, i.e. one can replace f(x) with x %&gt;% f(). The pipe makes code significantly more readable by avoiding nested function calls, reducing the need for intermediate variables, and making sequential operations read left-to-right. For example, to add a new variable to a data frame, then summarize using a grouping variable, the following are equivalent: library(dplyr) # pipes mtcars %&gt;% mutate(wt_kg = 454 * wt) %&gt;% group_by(cyl) %&gt;% summarize(wt_kg = mean(wt_kg)) #&gt; # A tibble: 3 x 2 #&gt; cyl wt_kg #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 1038. #&gt; 2 6 1415. #&gt; 3 8 1816. # intermediate variables mtcars_kg &lt;- mutate(mtcars, wt_kg = 454 * wt) mtcars_grouped &lt;- group_by(mtcars_kg, cyl) summarize(mtcars_grouped, wt_kg = mean(wt_kg)) #&gt; # A tibble: 3 x 2 #&gt; cyl wt_kg #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 1038. #&gt; 2 6 1415. #&gt; 3 8 1816. # nested function calls summarize( group_by( mutate(mtcars, wt_kg = 454 * wt), cyl ), wt_kg = mean(wt_kg) ) #&gt; # A tibble: 3 x 2 #&gt; cyl wt_kg #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4 1038. #&gt; 2 6 1415. #&gt; 3 8 1816. 1.3.6 GIS data Throughout this book, we’ll be producing maps of species distributions. To provide context for these distributions, we’ll need GIS data for political boundaries. Natural Earth is the best source for a range of tightly integrated vector and raster GIS data for producing professional cartographic maps. The R package, rnaturalearth provides a convenient method for accessing these data from within R. We’ll also need Bird Conservation Region (BCR) boundaries, which are available through Bird Studies Canada. In the following code, we download and prepare a variety of GIS layers, then save them all within a GeoPackage in the data/ subdirectory of the project. This will allow us to load these data in later chapters as they’re needed. library(sf) library(rnaturalearth) library(dplyr) f_ne &lt;- &quot;data/gis-data.gpkg&quot; # download bcrs tmp_dir &lt;- tempdir() tmp_bcr &lt;- file.path(tmp_dir, &quot;bcr.zip&quot;) paste0(&quot;https://www.birdscanada.org/research/gislab/download/&quot;, &quot;bcr_terrestrial_shape.zip&quot;) %&gt;% download.file(destfile = tmp_bcr) unzip(tmp_bcr, exdir = tmp_dir) bcr &lt;- file.path(tmp_dir, &quot;BCR_Terrestrial_master_International.shp&quot;) %&gt;% read_sf() %&gt;% select(bcr_code = BCR, bcr_name = LABEL) %&gt;% filter(bcr_code == 27) # clean up list.files(tmp_dir, &quot;bcr&quot;, ignore.case = TRUE, full.names = TRUE) %&gt;% unlink() # political boundaries # land border with lakes removed ne_land &lt;- ne_download(scale = 50, category = &quot;cultural&quot;, type = &quot;admin_0_countries_lakes&quot;, returnclass = &quot;sf&quot;) %&gt;% filter(CONTINENT == &quot;North America&quot;) %&gt;% st_set_precision(1e6) %&gt;% st_union() # country lines ne_country_lines &lt;- ne_download(scale = 50, category = &quot;cultural&quot;, type = &quot;admin_0_boundary_lines_land&quot;, returnclass = &quot;sf&quot;) %&gt;% st_geometry() ne_country_lines &lt;- st_intersects(ne_country_lines, ne_land, sparse = FALSE) %&gt;% as.logical() %&gt;% {ne_country_lines[., ]} # states, north america ne_state_lines &lt;- ne_download(scale = 50, category = &quot;cultural&quot;, type = &quot;admin_1_states_provinces_lines&quot;, returnclass = &quot;sf&quot;) %&gt;% filter(adm0_a3 %in% c(&quot;USA&quot;, &quot;CAN&quot;)) %&gt;% mutate(iso_a2 = recode(adm0_a3, USA = &quot;US&quot;, CAN = &quot;CAN&quot;)) %&gt;% select(country = adm0_name, country_code = iso_a2) # output unlink(f_ne) write_sf(ne_land, f_ne, &quot;ne_land&quot;) write_sf(ne_country_lines, f_ne, &quot;ne_country_lines&quot;) write_sf(ne_state_lines, f_ne, &quot;ne_state_lines&quot;) write_sf(bcr, f_ne, &quot;bcr&quot;) References "],
["ebird.html", "Chapter 2 eBird Data 2.1 Introduction 2.2 Data extraction with auk 2.3 Importing and zero-filling 2.4 Accounting for variation in detectability 2.5 Exploratory analysis and visualization", " Chapter 2 eBird Data 2.1 Introduction eBird data are collected and organized around the concept of a checklist, representing observations from a single birding event, such as a 1 km walk through a park or 15 minutes observing bird feeders in your backyard. Each checklist contains a list of species observed, counts of the number of individuals seen of each species, the location and time of the observations, and a measure of the effort expended while collecting these data. The following image depicts a typical eBird checklist as viewed on the eBird website: Although eBird collects semi-structured citizen science data, three elements of eBird checklists distinguish them from similar sources. First, eBird checklist require users to specify the survey protocol they used, whether it’s traveling, stationary, incidental (i.e. if the observations were collected when birding was not the primary activity), or one of the other protocols. Second, in addition to typical information on when and where the data were collected, checklists contain effort information specifying how long the observer searched, how far they traveled, and how many observers were part of the party. Finally, observers are asked to indicate whether they are reporting all the birds they were able to identify. Checklists with all species reported, known as complete checklists, enable researchers to identify which species were not detected (rather than just not reported). These inferred non-detections allow data to be zero-filled, so there’s a zero count for any species not recorded. Complete checklists with effort information facilitate robust analyses, and thus represent the gold standard of eBird checklists. Because of these factors, eBird data are often referred to as semi-structured (Kelling et al. 2018). Access to the complete set of eBird observations is provided via the eBird Basic Dataset (EBD). This is a tab-separated text file, released monthly, containing all validated bird sightings in the eBird database at the time of release. Each row corresponds to the sighting of a single species within a checklist and, in addition to the species and number of individuals reported, information is provided about the checklist (location, time, date, search effort, etc.). An additional file, the Sampling Event Data (SED), provides just the checklist data. In this file, each row corresponds to a checklist and only the checklist variables are included, not the associated species data. For complete checklists, the SED provides the full set of checklists in the database, which is needed to zero-fill the data. In particular, if a checklist is complete and doesn’t report a species, we can infer that there is a 0 count for that species on that checklist. In addition, checklists with no species recorded (yes, there exist), will not appear in the EBD, so the SED is required to identify these checklists. In the previous chapter, we described how to access and download the EBD. In this chapter, we’ll demonstrate how to use the R package auk to extract subsets of the data for analysis. We’ll show how to import the data into R and perform some pre-processing steps required to ensure proper analysis of the data. Finally, we’ll zero-fill the data to produce presence-absence eBird data suitable for modeling species distribution and abundance. In the interest of making examples concrete, throughout this chapter, and those that follow, we’ll use the specific example of Wood Thrush in Bird Conservation Region (BCR) 27 (“Southeastern Coastal Plains”) in June for our analyses. Before we get started, we suggest creating a new RStudio project for following along with these examples; this will ensure your working directory is always the project directory and allow us to use relative path. 2.1.1 eBird taxonomy eBird uses its own taxonomic system, updated annually after expert review every August. A notable benefit of these annual, system-wide updates is that splits and lumps are nearly instantly propagated across the entire eBird database. When necessary, expert reviewers manually sort through observations and assign records to current taxonomic hypotheses to the extent possible. This ensures that both new and historical eBird data conform to the updated taxonomy. In addition, after the taxonomy update, both the EBD and auk are updated to reflect the changes. We emphasize that for any eBird analysis, you should consider the taxonomy of your study organisms, and whether you’re accessing the intended data from eBird. For example, are you interested in all Willets or do you want to treat the eastern and western populations separately since they’re completely allopatric on their breeding grounds? Do you want to do an analysis combining Greater and Lesser Yellowlegs? eBirders have the option of recording observations for taxa above (e.g. at genus level) or below (e.g. at subspecies level) the species level. These more granular taxonomic assignments are available in the EBD. In many cases taxonomic differences can be dealt with by querying specific subspecies, or multiple species, and splitting and lumping after the query as necessary. However, note that the majority of eBird users don’t assign their observations to subspecies, so querying taxa below species will result in a much smaller dataset. If you’re not interested in these taxonomic nuances, auk will handle the taxonomy seamlessly for you by resolving all observations to species level. Indeed, for the example in this chapter, we’ll use all Wood Thrush observations and not delve into taxonomic issues further. 2.2 Data extraction with auk eBird contains an impressive amount of data (nearly 600 million bird observations!); however, this makes the EBD particularly challenging to work with due to its sheer size (over 200 GB!). Text files of this size can’t be opened in R, Excel, or most other software. Fortunately, the R package auk has been specifically designed to extract subsets of data from the EBD for analysis using the Unix command line text processing utility AWK. The goal when using auk should always be to subset the full EBD down to a manageable size, small enough that it can be imported into R for further processing or analysis. In our case, that will mean extracting Wood Thrush records from BCR 27 in June. Filtering the EDB using auk requires three steps. First, reference the EBD and SED using the function auk_ebd(). If you’ve followed the instruction in the Introduction for downloading eBird data, you’ll have these files on your computer and will have pointed auk to the directory they’re stored in using auk_set_ebd_path(). If you intend to zero-fill the data, you’ll need to pass both the EBD and SED to auk_ebd(), this ensures that the same set of filters is applied to both files so they contain the same population of checklists. It’s critical that the EBD and SED are both from the same release of the eBird data. library(auk) library(lubridate) library(sf) library(gridExtra) library(tidyverse) # resolve namespace conflicts select &lt;- dplyr::select ebd &lt;- auk_ebd(&quot;ebd_relDec-2018.txt&quot;, file_sampling = &quot;ebd_sampling_relDec-2018.txt&quot;) Next, define the filters that you want to apply to the EBD. Each field that you can filter on has an associated function. For example, we’ll filter to Wood Thrush observations with auk_species(), from BCR 27 with auk_bcr(), in June of any year with auk_date(), restrict observations to those from either Stationary or Traveling protocols with auk_protocol(), and only use complete checklists auk_complete() since we intend to zero-fill the data. For a full list of possible filters, consult the package documentation. ebd_filters &lt;- ebd %&gt;% auk_species(&quot;Wood Thrush&quot;) %&gt;% # southeastern coastal plain bcr auk_bcr(bcr = 27) %&gt;% # june, use * to get data from any year auk_date(date = c(&quot;*-06-01&quot;, &quot;*-06-30&quot;)) %&gt;% # restrict to the standard traveling and stationary count protocols auk_protocol(protocol = c(&quot;Stationary&quot;, &quot;Traveling&quot;)) %&gt;% auk_complete() ebd_filters #&gt; Input #&gt; EBD: /Users/mes335/data/ebird/ebd_relDec-2018.txt #&gt; Sampling events: /Users/mes335/data/ebird/ebd_sampling_relDec-2018.txt #&gt; #&gt; Output #&gt; Filters not executed #&gt; #&gt; Filters #&gt; Species: Hylocichla mustelina #&gt; Countries: all #&gt; States: all #&gt; BCRs: 27 #&gt; Bounding box: full extent #&gt; Date: *-06-01 - *-06-30 #&gt; Start time: all #&gt; Last edited date: all #&gt; Protocol: Stationary, Traveling #&gt; Project code: all #&gt; Duration: all #&gt; Distance travelled: all #&gt; Records with breeding codes only: no #&gt; Complete checklists only: yes Note that printing the object ebd_filters shows what filters have been set. At this point, we’ve only defined the filters, not applied them to the EBD. The last step is to use auk_filter() to compile the filters into an AWK script and run it to produce two output files: one for the EBD and one for the SED. This step typically takes several hours to run since the files are so large. As a result, it’s wise to wrap this in an if statement, so it’s only run once. # output files f_ebd &lt;- &quot;data/ebd_woothr_june_bcr27.txt&quot; f_sampling &lt;- &quot;data/ebd_june_bcr27_sampling.txt&quot; # only run if the files don&#39;t already exist if (!file.exists(f_ebd)) { auk_filter(ebd_filters, file = f_ebd, file_sampling = f_sampling) } These files are now a few megabytes rather than hundreds of gigabytes, which means they can easily be read into R! Don’t feel like waiting for auk_filter() to run? Download the data package mentioned in the introduction to get a copy of the EBD subset for Wood Thrush in June in BCR27 and proceed to the next section. 2.3 Importing and zero-filling The previous step left us with two tab separated text files, one for the EBD and one for the SED. Next, we’ll use auk_zerofill() to read these two files into R and combine them together to produce zero-filled, detection/non-detection data (also called presence/absence data). To just read the EBD or Sampling Event Data, but not combine them, use read_ebd() or read_sampling(), respectively. ebd_zf &lt;- auk_zerofill(f_ebd, f_sampling, collapse = TRUE) When any of the read functions from auk are used, two important processing steps occur by default behind the scenes. First, eBird observations can be made at levels below species (e.g. subspecies) or above species (e.g. hybrids); however, for most uses we’ll want observations at the species level. auk_rollup() is applied by default when auk_zerofill() is used, and it drops all observations not identifiable to a species and rolls up all observations reported below species to the species level. eBird also allows for group checklists, those shared by multiple users. These checklists lead to duplication or near duplication of records within the dataset and the function auk_unique(), applied by default by auk_zerofill(), addresses this by only keeping one independent copy of each checklist. Finally, by default auk_zerofill() retuns a compact representation of the data, consisting of a list of two data frames, one with checklist data and the other with observation data; the use of collapse = TRUE combines these into a single data frame, which will be easier to work with. Before continuing, we’ll transform some of the variables to a more useful form for modelling. We convert time to a decimal value between 0 and 24, and we force the distance travelled to 0 for stationary checklists. Notably, eBirders have the option of entering an “X” rather than a count for a species, to indicate that the species was present, but they didn’t keep track of how many were observed. During the modeling stage, we’ll want the observation_count variable stored as an integer and we’ll convert “X” to NA to allow this. # function to convert time observation to hours since midnight time_to_decimal &lt;- function(x) { x &lt;- hms(x, quiet = TRUE) hour(x) + minute(x) / 60 + second(x) / 3600 } # clean up variables ebd_zf &lt;- ebd_zf %&gt;% mutate( # convert X to NA observation_count = if_else(observation_count == &quot;X&quot;, NA_character_, observation_count), observation_count = as.integer(observation_count), # effort_distance_km to 0 for non-travelling counts effort_distance_km = if_else(protocol_type != &quot;Traveling&quot;, 0, effort_distance_km), # convert time to decimal hours since midnight time_observations_started = time_to_decimal(time_observations_started) ) 2.4 Accounting for variation in detectability As discussed in the Introduction, variation in effort between checklists makes inference challenging, because it is associated with variation in detectability. When working with semi-structured datasets like eBird, one approach to dealing with this variation is to impose some more consistent structure on the data by filtering observations on the effort variables. This reduces the variation in detectability between checklists. Based on our experience working with these data, we suggest restricting checklists to less than 5 hours long and 5 km in length, and with 10 or fewer observers. Furthermore, we’ll only consider data from the past 10 years (2009-2018). # additional filtering ebd_zf_filtered &lt;- ebd_zf %&gt;% filter( # effort filters duration_minutes &lt;= 5 * 60, effort_distance_km &lt;= 5, # last 10 years of data year(observation_date) &gt;= 2009, # 10 or fewer observers number_observers &lt;= 10) Finally, there are a large number of variables in the EBD that are redundant (e.g. country and state names and codes) or unnecessary for most modeling exercises (e.g. checklist comments and Important Bird Area (IBA) code). These can be removed at this point, keeping only the variables we want for modelling. Then we’ll save the resulting zero-filled observations for use in later chapters. ebird &lt;- ebd_zf_filtered %&gt;% select(checklist_id, observer_id, sampling_event_identifier, scientific_name, observation_count, species_observed, state_code, locality_id, latitude, longitude, protocol_type, all_species_reported, observation_date, time_observations_started, duration_minutes, effort_distance_km, number_observers) write_csv(ebird, &quot;data/ebd_woothr_june_bcr27_zf.csv&quot;, na = &quot;&quot;) If you’d like to ensure you’re using exactly the same data as was used to generate this book, download the data package mentioned in the setup instructions. 2.5 Exploratory analysis and visualization Before proceeding to fitting species distribution models with these data, it’s worth exploring the dataset to see what we’re working with. Let’s start by making a simple map of the observations. This map uses GIS data prepared in the introduction and available for download here. # load and project gis data map_proj &lt;- st_crs(102003) ne_land &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_land&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() bcr &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;bcr&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_country_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_country_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_state_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_state_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() # prepare ebird data for mapping ebird_sf &lt;- ebird %&gt;% # convert to spatial points st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) %&gt;% st_transform(crs = map_proj) %&gt;% select(species_observed) # map par(mar = c(0.25, 0.25, 0.25, 0.25)) # set up plot area plot(st_geometry(ebird_sf), col = NA) # contextual gis data plot(ne_land, col = &quot;#dddddd&quot;, border = &quot;#888888&quot;, lwd = 0.5, add = TRUE) plot(bcr, col = &quot;#cccccc&quot;, border = NA, add = TRUE) plot(ne_state_lines, col = &quot;#ffffff&quot;, lwd = 0.75, add = TRUE) plot(ne_country_lines, col = &quot;#ffffff&quot;, lwd = 1.5, add = TRUE) # ebird observations # not observed plot(st_geometry(ebird_sf), pch = 19, cex = 0.1, col = alpha(&quot;#555555&quot;, 0.25), add = TRUE) # observed plot(filter(ebird_sf, species_observed) %&gt;% st_geometry(), pch = 19, cex = 0.3, col = alpha(&quot;#4daf4a&quot;, 1), add = TRUE) # legend legend(&quot;bottomright&quot;, bty = &quot;n&quot;, col = c(&quot;#555555&quot;, &quot;#4daf4a&quot;), legend = c(&quot;eBird checklists&quot;, &quot;Wood Thrush sightings&quot;), pch = 19) box() par(new = TRUE, mar = c(0, 0, 3, 0)) title(&quot;Wood Thrush eBird Observations\\nJune 2009-2018, BCR 27&quot;) In this map, the spatial bias in eBird data becomes immediately obvious, for example, notice the large number of checklists along the heavily populated Atlantic coast, especially around large cities like Jacksonville, Florida and popular birding areas like the Outer Banks of North Carolina. It’s also valuable to explore some of the effort variables. In particular, we’ll look at the range of effort variables in the data and where the majority of the observations fall. For values of the effort covariates for which we have few observations, our models will likely not perform well. 2.5.1 Time of day The chance of an observer detecting a bird when present can be highly dependent on time of day. For example, many species exhibit a peak in detection early in the morning during dawn chorus and a secondary peak early in the evening. With this in mind, the first predictor of detection that we’ll explore is the time of day at which a checklist was started. # histogram g_tod_hist &lt;- ggplot(ebird) + aes(x = time_observations_started) + geom_histogram(binwidth = 1, center = 0, color = &quot;grey30&quot;, fill = &quot;grey50&quot;) + scale_x_continuous(breaks = seq(0, 24, by = 3)) + scale_y_continuous(labels = scales::comma) + labs(x = &quot;Hours since midnight&quot;, y = &quot;# checklists&quot;, title = &quot;Distribution of observation start times&quot;) # histogram of detections g_tod_hist_det &lt;- ggplot(filter(ebird, species_observed)) + aes(x = time_observations_started) + geom_histogram(binwidth = 1, center = 0, color = &quot;grey30&quot;, fill = &quot;grey50&quot;) + scale_x_continuous(breaks = seq(0, 24, by = 3)) + scale_y_continuous(labels = scales::comma) + labs(x = &quot;Hours since midnight&quot;, y = &quot;# checklists w/ detections&quot;, title = &quot;Distribution of start times for checklists with detections&quot;) # combine grid.arrange(g_tod_hist, g_tod_hist_det) The peak frequency of checklist submissions, and of those checklists with detections, occurs between 6 and 9 am. Therefore, further filtering to a subset of time during the day (e.g. 5am to 12pm) will help reduce variability in detection without reducing the total number of observations significantly. 2.5.2 Checklist duration When we initially extracted the eBird data in Section @ref{ebird-extract}, we restricted observations to those from checklists 5 hours in duration or shorter to reduce variability. Let’s see what sort of variation remains in checklist duration. # histogram g_dur_hist &lt;- ggplot(ebird) + aes(x = duration_minutes / 60) + geom_histogram(binwidth = 0.5, center = 0.25, color = &quot;grey20&quot;, fill = &quot;grey50&quot;) + scale_x_continuous(breaks = 0:5) + scale_y_continuous(labels = scales::comma) + labs(x = &quot;Checklist duration (hours)&quot;, y = &quot;# checklists&quot;, title = &quot;Distribution of checklist durations&quot;) # histogram of detections g_dur_hist_det &lt;- ggplot(filter(ebird, species_observed)) + aes(x = duration_minutes / 60) + geom_histogram(binwidth = 0.5, center = 0.25, color = &quot;grey20&quot;, fill = &quot;grey50&quot;) + scale_x_continuous(breaks = 0:5) + scale_y_continuous(labels = scales::comma) + labs(x = &quot;Checklist duration (hours)&quot;, y = &quot;# checklists w/ detections&quot;, title = &quot;Distribution of durations for checklists with detections&quot;) # combine grid.arrange(g_dur_hist, g_dur_hist_det) The majority of checklists are half an hour or shorter and there is a rapid decline in the frequency of checklists with increasing duration. Therefore, filtering checklists to less than one hour will reduce variation in detection with checklist duration. 2.5.3 Distance traveled As with checklist duration, we expect a priori that the greater the distance someone travels, the greater the probability of encountering at least one Wood Thrush. Let’s see if this expectation is met. Note that we have already truncated the data to checklists less than 5 km in length. # histogram g_dist_hist &lt;- ggplot(ebird) + aes(x = effort_distance_km) + geom_histogram(binwidth = 0.5, center = 0.25, color = &quot;grey20&quot;, fill = &quot;grey50&quot;) + scale_x_continuous(breaks = 0:5) + scale_y_continuous(labels = scales::comma) + labs(x = &quot;Distance travelled (km)&quot;, y = &quot;# checklists&quot;, title = &quot;Distribution of distance travelled&quot;) # histogram of detections g_dist_hist_det &lt;- ggplot(filter(ebird, species_observed)) + aes(x = effort_distance_km) + geom_histogram(binwidth = 0.5, center = 0.25, color = &quot;grey20&quot;, fill = &quot;grey50&quot;) + scale_x_continuous(breaks = 0:5) + scale_y_continuous(labels = scales::comma) + labs(x = &quot;Distance travelled (km)&quot;, y = &quot;# checklists&quot;, title = paste(&quot;Distribution of distance travelled&quot;, &quot;for checklists with detections&quot;)) # combine grid.arrange(g_dist_hist, g_dist_hist_det) As with duration, the majority of observations are from short checklists (less than half a kilometer). One fortunate consequence of this is that most checklists will be contained within a small area within which habitat is not likely to show high variability. In chapter @ref{habitat}, we summarized habitat within circles having a 2.5 km diameter, centered on each checklist, and it appears that the vast majority of checklists willl stay contained within this area. As with other variables, eliminating checklists that are greater than one kilometer will increase the spatial accuracy of the observations and not significantly reduce sample sizes. 2.5.4 Number of observers Next, let’s consider the number of observers whose observation are being reported in each checklist. We expect that at least up to some number of observers, reporting rates will increase; however, in working with these data we have found cases of declining detection rates for very large groups. Note that the data have been restricted to checklists with 10 or fewer observers, already removing the very largest groups (prior to filtering, some checklists had as many as 230 observers!). # histogram g_obs_hist &lt;- ggplot(ebird) + aes(x = number_observers) + geom_histogram(binwidth = 1, center = 1, color = &quot;grey20&quot;, fill = &quot;grey50&quot;) + scale_x_continuous(breaks = 1:10) + scale_y_continuous(labels = scales::comma) + labs(x = &quot;# of observers&quot;, y = &quot;# checklists&quot;, title = &quot;Distribution of number of observers&quot;) # histogram of detections g_obs_hist_det &lt;- ggplot(filter(ebird, species_observed)) + aes(x = number_observers) + geom_histogram(binwidth = 1, center = 1, color = &quot;grey20&quot;, fill = &quot;grey50&quot;) + scale_x_continuous(breaks = 1:10) + scale_y_continuous(labels = scales::comma) + labs(x = &quot;# of observers&quot;, y = &quot;# checklists&quot;, title = paste(&quot;Distribution of number of observers&quot;, &quot;for checklists with detections&quot;)) grid.arrange(g_obs_hist, g_obs_hist_det) Due to the very small sample sizes of records with 3 or more observers, reducing the number of checklists from 40,477 to 40,059 records will reduce the need to model the number of observers as a covariate for detection, and not significantly reduce sample size. References "],
["habitat.html", "Chapter 3 Habitat Covariates 3.1 Introduction 3.2 Downloading MODIS data 3.3 Landscape metrics 3.4 Prediction surface", " Chapter 3 Habitat Covariates 3.1 Introduction Species distribution models work by finding associations between species occurrence or abundance and environmental variables. Using these relationships, it’s possible to predict the distribution in areas that aren’t sampled, provided we know the value of the environmental variables in these areas. Therefore, to proceed with the modeling in the next several chapters, we’ll need to prepare a suite of environmental variables to be used as covariates in our models. The particular set of covariates that’s most suitable for a given study will depend on the focal species, region, and time period, as well as the availability of data. Fortunately, there is an abundance of freely available, satellite-based landcover products derived from satellites such as Landsat, SPOT, and MODIS that are suitable for distribution modeling. For the examples in this book, we’ll use habitat covariates derived from the MODIS MCD12Q1 v006 landcover product (Friedl and Sulla-Menashe 2015). This product has global coverage at 500 m spatial resolution and annual temporal resolution from 2001-2017. These data are available for several different classification schemes. We’ll use the University of Maryland (UMD) landcover classification, which provides a globally accurate classification of landcover in our experience. This system classifies pixels into one of 16 different landcover classes: Class Name Description 0 Water bodies At least 60% of area is covered by permanent water bodies. 1 Evergreen Needleleaf Forests Dominated by evergreen conifer trees (canopy &gt;2m). Tree cover &gt;60%. 2 Evergreen Broadleaf Forests Dominated by evergreen broadleaf and palmate trees (canopy &gt;2m). Tree cover &gt;60%. 3 Deciduous Needleleaf Forests Dominated by deciduous needleleaf (e.g. larch) trees (canopy &gt;2m). Tree cover &gt;60%. 4 Deciduous Broadleaf Forests Dominated by deciduous broadleaf trees (canopy &gt;2m). Tree cover &gt;60%. 5 Mixed Forests Dominated by neither deciduous nor evergreen (40-60% of each) tree type (canopy &gt;2m). Tree cover &gt;60%. 6 Closed Shrublands Dominated by woody perennials (1-2m height) &gt;60% cover. 7 Open Shrublands Dominated by woody perennials (1-2m height) 10-60% cover. 8 Woody Savannas Tree cover 30-60% (canopy &gt;2m). 9 Savannas Tree cover 10-30% (canopy &gt;2m). 10 Grasslands Dominated by herbaceous annuals (&lt;2m). 11 Permanent Wetlands Permanently inundated lands with 30-60% water cover and &gt;10% vegetated cover. 12 Croplands At least 60% of area is cultivated cropland. 13 Urban and Built-up Lands At least 30% impervious surface area including building materials, asphalt, and vehicles. 14 Cropland/Natural Vegetation Mosaics Mosaics of small-scale cultivation 40-60% with natural tree, shrub, or herbaceous vegetation. 15 Non-Vegetated Lands At least 60% of area is non-vegetated barren (sand, rock, soil) or permanent snow and ice with less than 10% vegetation. 255 Unclassified Has not received a map label because of missing inputs. For a wide range of studies, this MODIS landcover dataset will be suitable for generating habitat covariates; however, there may be particular cases where the study species, habitat, or ecological question requires different, or more specialized, data. For example, shorebird distribution modeling would benefit from data on the extent of tidal flats, seabirds distributions are often influenced by ocean depth, and in many regions elevation plays a critical role in shaping species distributions. Regardless of which habitat data you decide to use for your project, this chapter should provide a template for how to prepare these data as covariates for modeling species distributions. The next section will cover how to access and download MODIS landcover data. Next, we’ll demonstrate how to summarize these data within a neighborhood around each checklist location. Finally, we’ll calculate a set of covariates over a regular grid, which we’ll use to make predictions of species distributions throughout our study area. If you want to skip this section and jump straight to the modeling, you can download the data package, which includes all the prepared MODIS data that we’ll use in the remainder of this book. 3.2 Downloading MODIS data As with most satellite data, MODIS data are provided as 1200 km by 1200 km tiles for ease of download. Each tile is a raster GIS dataset consisting of a regular grid of 500 m resolution cells. The surface of the Earth is divided up into a grid of these tiles, each given an ID, for example, h10v12 is the tile from the 10th column and 12th row of the grid. Compiling MODIS data for a given region requires figuring out which set of tiles covers the region, downloading those tiles, combining the tiles together into a single raster dataset, and converting from the native MODIS HDF format, which R can’t read, to a standard GeoTIFF format. This needs to be done for each year for which we want habitat data, and can be a time consuming and error prone process. Fortunately, the R package MODIS automates most of these steps. Unfortunately, this package can be challenging to set up and has a confusing user interface. With this in mind, this section will provide detailed instruction for setting up and using the MODIS package. Let’s start by figuring out the tile IDs for the tiles that BCR 27 spans. Recall that we prepared a BCR boundary in Section 1.3.6 of the Introduction; if you haven’t already done so, download the data package now to get that boundary. Given a set of spatial features, the MODIS package can quickly tell us which MODIS tiles we need. library(sf) library(raster) library(MODIS) library(velox) library(viridis) library(tidyverse) # resolve namespace conflicts select &lt;- dplyr::select projection &lt;- raster::projection # bcr 27 boundary bcr &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;bcr&quot;) %&gt;% filter(bcr_code == 27) # load ebird data ebird &lt;- read_csv(&quot;data/ebd_woothr_june_bcr27_zf.csv&quot;) # get list of tiles required to cover this bcr tiles &lt;- getTile(bcr) tiles@tile #&gt; [1] &quot;h10v06&quot; &quot;h10v05&quot; &quot;h11v05&quot; So, we’ll need to download these three tiles for each of the 10 years from 2009-2018: . 3.2.1 Download using R Before we start using MODIS for the first time, a bit of setup is required. First, sign up for a NASA Earthdata account to get access to MODIS, and other NASA data. Then use MODIS::EarthdataLogin(usr = &quot;username&quot;, pwd = &quot;password&quot;), with the username and password you just created, to store your login credentials so the MODIS package can access them. Next, install GDAL, an open source library for working with geospatial data that’s needed for processing the MODIS tiles. The steps for installing GDAL are system dependent: Mac OS X: install the Homebrew package manager, then run brew install gdal in the terminal. Linux: run sudo apt-get install gdal-bin in the terminal. Windows: install OSGeo4W, a suite of open source geospatial tools that includes GDAL. In R, run MODIS:::checkTools(&quot;GDAL&quot;), which will search your system for GDAL and suggest a command such as MODIS::MODISoptions(gdalPath = &quot;c:/OSGeo4W64/bin&quot;) that will make GDAL available to the MODIS package. Run this command and, when it asks, agree to making the settings permanent. Finally, run MODIS:::checkTools(&quot;GDAL&quot;) to check that GDAL is installed and that the MODIS package can find it. If GDAL can’t be found, you’ll need to manually locate it and use MODIS::MODISoptions(gdalPath = &quot;path/to/gdal/&quot;) to tell the MODIS package where it is. Once all the setup steps have been completed, we can start downloading some data! The MODIS function runGdal() downloads and processes MODIS tiles into a single GeoTIFF for each year. Note that at the time of writing, landcover data from 2018 haven’t been prepared yet, so we’ll use 2017 data for both 2017 and 2018. The key arguments to runGdal() are: product: is the specific MODIS product to download. For a full list of available datasets use MODIS::getProduct(). SDSstring: a string specifying which bands to extract, with zeros for bands to drop and 1 for bands to keep. Most MODIS products have multiple bands stored in a single raster file, for example, reflectances in different wavelength ranges or, in our case, landcover using different landcover classification systems. The documentation for the MCD12Q1 dataset shows that there are 13 bands in the downloaded files, and we’re interested in band 2, which contains the UMD landcover classification. tileH and tileV: the vertical and horizontal tile numbers as returned by getTile(). begin and end: the start and end dates of of the time period from which to extract data. Although the landcover data are only available annually, we need to specify full dates because some other products are available on a more granular basis. outDirPath: directory to store processed MODIS data. job: a name for this task, which will become the sub-directory of outDirPath within which the processed data are stored. # earliest year of ebird data begin_year &lt;- format(min(ebird$observation_date), &quot;%Y.01.01&quot;) # end date for ebird data, mcd12q1 only exists up to 2017 end_year &lt;- min(format(max(ebird$observation_date), &quot;%Y.12.31&quot;), &quot;2017.12.31&quot;) # download tiles and combine into a single raster for each year tifs &lt;- runGdal(product = &quot;MCD12Q1.006&quot;, SDSstring = &quot;01&quot;, tileH = tiles@tileH, tileV = tiles@tileV, begin = begin_year, end = end_year, outDirPath = &quot;data&quot;, job = &quot;modis&quot;) %&gt;% pluck(&quot;MCD12Q1.006&quot;) %&gt;% unlist() # rename tifs to have more descriptive names new_names &lt;- format(as.Date(names(tifs)), &quot;%Y&quot;) %&gt;% sprintf(&quot;modis_mcd12q1_umd_%s.tif&quot;, .) %&gt;% file.path(dirname(tifs), .) file.rename(tifs, new_names) If everything ran smoothly, we now have annual GeoTIFFs of MODIS landcover data from 2010 to 2017 that we can load into R. landcover &lt;- list.files(&quot;data/modis&quot;, &quot;^modis_mcd12q1_umd&quot;, full.names = TRUE) %&gt;% stack() # label layers with year landcover &lt;- names(landcover) %&gt;% str_extract(&quot;(?&lt;=modis_mcd12q1_umd_)[0-9]{4}&quot;) %&gt;% paste0(&quot;y&quot;, .) %&gt;% setNames(landcover, .) landcover #&gt; class : RasterStack #&gt; dimensions : 4800, 4800, 2.3e+07, 9 (nrow, ncol, ncell, nlayers) #&gt; resolution : 463, 463 (x, y) #&gt; extent : -8895604, -6671703, 2223901, 4447802 (xmin, xmax, ymin, ymax) #&gt; coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs #&gt; names : y2009, y2010, y2011, y2012, y2013, y2014, y2015, y2016, y2017 #&gt; min values : 0, 0, 0, 0, 0, 0, 0, 0, 0 #&gt; max values : 255, 255, 255, 255, 255, 255, 255, 255, 255 3.3 Landscape metrics At this point we could use the MODIS landcover data directly, simply extracting the landcover class for each checklist location. However, we instead advocate summarizing the landcover data within a neighborhood around the checklist locations. As discussed in Section 1.1, checklist locations are not precise, so it’s more appropriate to use the habitat in the surrounding area, rather than only at the checklist location. More fundamentally, organisms interact with their environment not at a single point, but at the scale of a landscape, so it’s important to include habitat information characterizing a suitably-sized landscape around the observation location. There are a variety of landscape metrics that can be used to characterize the composition (what habitat is available) and configuration (how that habitat is arranged spatially) of landscapes. The simplest metric of landscape composition is the percentage of the landscape in each landcover class (PLAND in the parlance of FRAGSTATS). For a broad range of scenarios, PLAND is a reliable choice for calculating habitat covariates in distribution modeling. Based on our experience working with eBird data, an approximately 2.5 km by 2.5 km square neighborhood (5 by 5 MODIS cells) centered on the checklist location is sufficient to account for the spatial precision in the data when the maximum distance of travelling counts has been limited to 5 km, while being a relevant ecological scale for many bird species. We’ll start by finding the full set of unique checklists locations for each year in the eBird data. Then we convert these locations to spatial sf features and project them to the sinusoidal equal area projection used by MODIS. We’ll buffer these points to create square polygons around each location that are the size of a 5 by 5 grid of MODIS landcover cells. Finally, we split the neighborhoods up by year so we can match to MODIS landcover data from the corresponding year. neighborhood_radius &lt;- 2.5 * ceiling(max(res(landcover))) ebird_locs &lt;- ebird %&gt;% distinct(year = format(observation_date, &quot;%Y&quot;), locality_id, latitude, longitude) %&gt;% st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) %&gt;% # transform to modis projection st_transform(crs = projection(landcover)) %&gt;% # buffer to create square neighborhood around each point st_buffer(dist = neighborhood_radius, endCapStyle = &quot;SQUARE&quot;) ebird_locs_year &lt;- split(ebird_locs, ebird_locs$year) Now, we’ll loop over the years and for each square neighborhood extract all the raster values within that neighborhood. We use the velox package for this, since it’s often orders of magnitude faster than using raster::extract(). for (yr in names(ebird_locs_year)) { # for 2018 use 2017 landcover data yr_lc &lt;- ifelse(as.integer(yr) &gt; 2017, &quot;2017&quot;, yr) %&gt;% paste0(&quot;y&quot;, .) # create a lookup table to get locality_id from row number locs &lt;- st_set_geometry(ebird_locs_year[[yr]], NULL) %&gt;% mutate(id = row_number()) # extract using velox lc_vlx &lt;- velox(landcover[[yr_lc]]) ebird_locs_year[[yr]] &lt;- lc_vlx$extract(ebird_locs_year[[yr]], df = TRUE) %&gt;% # velox doesn&#39;t properly name columns, fix that set_names(c(&quot;id&quot;, &quot;landcover&quot;)) %&gt;% # join to lookup table to get locality_id inner_join(locs, ., by = &quot;id&quot;) %&gt;% select(-id) } # combine years back together lc_extract &lt;- bind_rows(ebird_locs_year) Now we have the set of landcover values within a neighborhood around each checklist location. We can summarize these data within each neighborhood to calculate PLAND: the proportion of the neighborhood within each landcover class. pland &lt;- lc_extract %&gt;% # count landcovers count(locality_id, year, landcover) %&gt;% # calculate proporiton group_by(locality_id, year) %&gt;% mutate(pland = n / sum(n)) %&gt;% ungroup() %&gt;% select(-n) %&gt;% # remove NAs after tallying so pland is relative to total number of cells filter(!is.na(landcover)) # tranform to wide format, filling in implicit missing values with 0s pland &lt;- pland %&gt;% mutate(landcover = paste0(&quot;pland_&quot;, str_pad(landcover, 2, pad = &quot;0&quot;))) %&gt;% spread(landcover, pland, fill = 0) # save write_csv(pland, &quot;data/modis_pland_location-year.csv&quot;) 3.4 Prediction surface After fitting species distribution models, the goal is typically to make predictions throughout the study area. To do this, we’ll need a regular grid of habitat covariates over which to make predictions. In this section, we’ll create such a prediction surface for BCR 27 using the MODIS landcover data from 2017. To start, we’ll need a template raster with cells equal in size to the neighborhoods we defined in the previous section: 5 by 5 MODIS landcover cells. We can use raster::aggregate() to achieve this. We’ll also use raster::rasterize() to assign the value 1 to all cells within BCR 27 and leave all cells outside BCR 27 empty. agg_factor &lt;- round(2 * neighborhood_radius / res(landcover)) r &lt;- raster(landcover) %&gt;% aggregate(agg_factor) r &lt;- bcr %&gt;% st_transform(crs = projection(r)) %&gt;% rasterize(r, field = 1) %&gt;% # remove any empty cells at edges trim(filename = &quot;data/prediction-surface.tif&quot;, overwrite = TRUE) Next, for each cell of this raster, we’ll calculate the PLAND metrics using the same approach as the previous section. # get cell centers and create neighborhoods r_centers &lt;- rasterToPoints(r, spatial = TRUE) %&gt;% st_as_sf() %&gt;% transmute(id = row_number()) r_cells &lt;- st_buffer(r_centers, dist = neighborhood_radius, endCapStyle = &quot;SQUARE&quot;) # extract landcover values within neighborhoods, only need 2017 lc_vlx &lt;- velox(landcover[[&quot;y2017&quot;]]) lc_extract_pred &lt;- lc_vlx$extract(r_cells, df = TRUE) %&gt;% set_names(c(&quot;id&quot;, &quot;landcover&quot;)) %&gt;% filter(!is.na(landcover)) # calculate the percent for each landcover class pland_pred &lt;- lc_extract_pred %&gt;% count(id, landcover) %&gt;% group_by(id) %&gt;% mutate(pland = n / sum(n)) %&gt;% ungroup() %&gt;% select(-n) # tranform to wide format, filling in implicit missing values with 0s pland_pred &lt;- pland_pred %&gt;% mutate(landcover = paste0(&quot;pland_&quot;, str_pad(landcover, 2, pad = &quot;0&quot;))) %&gt;% spread(landcover, pland, fill = 0) %&gt;% mutate(year = 2017L) %&gt;% select(id, year, everything()) # join in coordinates pland_coords &lt;- st_transform(r_centers, crs = 4326) %&gt;% st_coordinates() %&gt;% as.data.frame() %&gt;% cbind(id = r_centers$id, .) %&gt;% rename(longitude = X, latitude = Y) %&gt;% inner_join(pland_pred, by = &quot;id&quot;) # save write_csv(pland_coords, &quot;data/modis_pland_prediction-surface.csv&quot;) glimpse(pland_coords) #&gt; Observations: 90,912 #&gt; Variables: 20 #&gt; $ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,… #&gt; $ longitude &lt;dbl&gt; -77.3, -77.3, -77.3, -77.2, -77.3, -77.3, -77.3, -77.3… #&gt; $ latitude &lt;dbl&gt; 37.3, 37.2, 37.2, 37.2, 37.2, 37.2, 37.2, 37.2, 37.2, … #&gt; $ year &lt;int&gt; 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, … #&gt; $ pland_00 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … #&gt; $ pland_01 &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, … #&gt; $ pland_02 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … #&gt; $ pland_03 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … #&gt; $ pland_04 &lt;dbl&gt; 0.24, 0.00, 0.00, 0.16, 0.08, 0.00, 0.00, 0.04, 0.08, … #&gt; $ pland_05 &lt;dbl&gt; 0.04, 0.00, 0.08, 0.00, 0.16, 0.04, 0.04, 0.12, 0.40, … #&gt; $ pland_06 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … #&gt; $ pland_07 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … #&gt; $ pland_08 &lt;dbl&gt; 0.72, 1.00, 0.88, 0.84, 0.64, 0.76, 0.68, 0.64, 0.52, … #&gt; $ pland_09 &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.12, 0.20, 0.28, 0.20, 0.00, … #&gt; $ pland_10 &lt;dbl&gt; 0.00, 0.00, 0.04, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, … #&gt; $ pland_11 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … #&gt; $ pland_12 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … #&gt; $ pland_13 &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, … #&gt; $ pland_14 &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, … #&gt; $ pland_15 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … Keeping these data in a data frame is a compact way to store them and will be required once we make model predictions in later chapters. However, we can always use the raster template to convert these PLAND metrics into a spatial format, for example, if we want to map them. Let’s look at how this works for landcover class 4: deciduous broadleaf forest. forest_cover &lt;- pland_coords %&gt;% # convert to spatial points st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) %&gt;% st_transform(crs = projection(r)) %&gt;% # rasterize points rasterize(r, field = &quot;pland_04&quot;) %&gt;% # project to albers equal-area for mapping projectRaster(crs = st_crs(102003)$proj4string, method = &quot;ngb&quot;) %&gt;% # trim off empty edges of raster trim() # make a map par(mar = c(0.25, 0.25, 2, 0.25)) plot(forest_cover, axes = FALSE, box = FALSE, col = viridis(10), main = &quot;Proportion of Deciduous Broadleaf Forest\\n2017 MODIS Landcover&quot;) This completes the data preparation and the remaining chapters will focus on using these data to predict species distributions. References "],
["encounter.html", "Chapter 4 Modeling Encounter Rate 4.1 Introduction 4.2 Data preparation 4.3 Spatiotemporal subsampling 4.4 Random forests 4.5 Environmental associations 4.6 Prediction", " Chapter 4 Modeling Encounter Rate 4.1 Introduction In this chapter we’ll estimate the encounter rate of Wood Thrush on eBird checklists in June in BCR 27. We define encounter rate as measuring the probability of an expert eBirder encountering a species on an standard eBird checklist, so that the calculated encounter rates approximate the actual occurrence rates of Wood Thrush. The ecological metric we’re ultimately interested in is the probability that a species occurs at a site (i.e. the occupancy probability). This is usually not possible with semi-structured citizen science data like those from eBird because we typically can’t estimate absolute detectability. However, by accounting for much of the variation in detectability by including effort covariaters in our model, the remaining unaccounted detectability will be more consistent across sites (Guillera-Arroita et al. 2015). Therefore, the encounter rate metric will be relative to occupancy up to a constant of detectability, allowing us to compare species distributions across space and time. Random forests are a general purpose machine learning method applicable to a wide range of classification and regression problems, including the task at hand: identifying predictors that classify reporting and non-reporting of a species on eBird checklists. In addition to good predictive performance, random forests are reasonably easy to use and have several efficient implementations in R. Prior to fitting a random forest model, we’ll demonstrate how to address issues of class imbalance and spatial bias using spatial subsampling on a regular grid. After fitting the model, we’ll assess its performance using a subset of data put aside for testing, and calibrate the model to ensure predictions are accurate. Finally, we’ll predict encounter rates throughout the study area and produce maps of these predictions. 4.2 Data preparation Let’s get started by loading the necessary packages and data. If you worked through the previous chapters, you should have all the data necessary for this chapter. However, you may want to download the data package, and unzip it to your working directory, to ensure you’re working with exactly the same data as was used in the creation of this book. Note that the Checklist Calibration Index (CCI), which calibrates observers and checklists against others from similar times and places, is an optional covariate in these models. Including CCI typical leads to marked improvement of model performance; however, due to the sensitive nature of these data you will need to download them separately after agree to the terms and conditions. If you’ve downloaded these data, put the CCI text file in the data/ subdirectory of your project. library(sf) library(raster) library(dggridR) library(lubridate) library(ranger) library(scam) library(PresenceAbsence) library(verification) library(edarf) library(viridis) library(fields) library(gridExtra) library(tidyverse) # resolve namespace conflicts select &lt;- dplyr::select projection &lt;- raster::projection set.seed(1) # ebird data ebird &lt;- read_csv(&quot;data/ebd_woothr_june_bcr27_zf.csv&quot;) %&gt;% # year required to join to habitat data mutate(year = year(observation_date)) # modis habitat covariates habitat &lt;- read_csv(&quot;data/modis_pland_location-year.csv&quot;) %&gt;% mutate(year = as.integer(year)) # combine ebird and habitat data ebird_habitat &lt;- inner_join(ebird, habitat, by = c(&quot;locality_id&quot;, &quot;year&quot;)) # optional checklist calibration index cci_file &lt;- &quot;data/cci_june_bcr27.csv&quot; if (file.exists(cci_file)) { cci &lt;- read_csv(cci_file) ebird_habitat &lt;- inner_join(ebird_habitat, cci, by = &quot;checklist_id&quot;) %&gt;% filter(!is.na(checklist_calibration_index)) } # prediction surface pred_surface &lt;- read_csv(&quot;data/modis_pland_prediction-surface.csv&quot;) r &lt;- raster(&quot;data/prediction-surface.tif&quot;) # load gis data for making maps map_proj &lt;- st_crs(102003) ne_land &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_land&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() bcr &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;bcr&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_country_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_country_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_state_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_state_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() 4.3 Spatiotemporal subsampling As discussed in the introduction, three of the challenges when using citizen science data, such as those from eBird, are spatial bias, temporal bias, and class imbalance. Spatial and temporal bias refers to the tendency of eBird checklists to be distributed non-randomly in space and time, while class imbalance refers to fact that there will be many more non-detections that detections for most species. All three can impact our ability to make reliable inferences from these data. Fortunately, all three can largely be addressed through subsampling the eBird data prior to modeling. In particular, we define an equal area hexagonal grid across the study region, then randomly sample one checklist from each grid cell for each week. To deal with class imbalance, we subsample detections and non-detections separately to ensure we don’t lose too many detections. Hexagonal grids seem exotic relative to square grids, which may be more familiar, however, they have a variety of benefits (Sahr 2011) including significantly less spatial distortion. With hexagonal grids we can be sure all the cells are of equal area, which is particularly important if we have a large region for modeling. The R package dggridR makes working with hexagonal grids simple and efficient. We’ll construct a grid with 5 km spacing between the centres of adjacent hexagons, then sample randomly from these hexagonal cells. Before working with the real data, it’s instructive to look at a small toy example, to see how this subsampling process works. We’ll generate a few hundred random points, overlay a hexagonal grid, then sample one point from each cell. # bounding box to generate points from bb &lt;- st_bbox(c(xmin = -0.1, xmax = 0.1, ymin = -0.1, ymax = 0.1), crs = 4326) %&gt;% st_as_sfc() %&gt;% st_sf() # random points, 10% detections pts &lt;- st_sample(bb, 500) %&gt;% st_sf(as.data.frame(st_coordinates(.)), geometry = .) %&gt;% rename(lat = Y, lon = X) # contruct a hexagonal grid with ~ 5 km between cells dggs &lt;- dgconstruct(spacing = 5) # for each point, get the grid cell pts$cell &lt;- dgGEO_to_SEQNUM(dggs, pts$lon, pts$lat)$seqnum # sample one checklist per grid cell per week pts_ss &lt;- pts %&gt;% group_by(cell) %&gt;% sample_n(size = 1) %&gt;% ungroup() # generate polygons for the grid cells hexagons &lt;- dgcellstogrid(dggs, unique(pts$cell), frame = FALSE) %&gt;% st_as_sf() ggplot() + geom_sf(data = hexagons) + geom_sf(data = pts, size = 0.5) + geom_sf(data = pts_ss, col = &quot;red&quot;) + theme_bw() Now let’s apply exactly the same approach to subsampling the real eBird checklists. # generate hexagonal grid with ~ 5 km betweeen cells dggs &lt;- dgconstruct(spacing = 5) # get hexagonal cell id and week number for each checklist checklist_cell &lt;- ebird_habitat %&gt;% mutate(cell = dgGEO_to_SEQNUM(dggs, longitude, latitude)$seqnum, week = week(observation_date)) # sample one checklist per grid cell per week # sample detection/non-detection independently ebird_ss &lt;- checklist_cell %&gt;% group_by(species_observed, week, cell) %&gt;% sample_n(size = 1) %&gt;% ungroup() How did this impact the prevalence of detections compared to non-detections? # original data nrow(ebird_habitat) #&gt; [1] 40477 count(ebird_habitat, species_observed) %&gt;% mutate(percent = n / sum(n)) #&gt; # A tibble: 2 x 3 #&gt; species_observed n percent #&gt; &lt;lgl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 FALSE 38539 0.952 #&gt; 2 TRUE 1938 0.0479 # after sampling nrow(ebird_ss) #&gt; [1] 10391 count(ebird_ss, species_observed) %&gt;% mutate(percent = n / sum(n)) #&gt; # A tibble: 2 x 3 #&gt; species_observed n percent #&gt; &lt;lgl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 FALSE 9201 0.885 #&gt; 2 TRUE 1190 0.115 So, the subsampling decreased the overall number of checklists by a factor of about four, but increased the prevalance of detections from 4.80% to 11.5%. This increase in detections will help the random forest model distinguish where birds are being observed; however, we will need to account for this change in prevalence by calibrating our model, which will be covered in Section 4.4.1. Let’s look at how the subsampling affects the spatial distribution of the observations. # convert checklists to spatial features all_pts &lt;- ebird_habitat %&gt;% st_as_sf(coords = c(&quot;longitude&quot;,&quot;latitude&quot;), crs = 4326) %&gt;% st_transform(crs = map_proj) %&gt;% select(species_observed) ss_pts &lt;- ebird_ss %&gt;% st_as_sf(coords = c(&quot;longitude&quot;,&quot;latitude&quot;), crs = 4326) %&gt;% st_transform(crs = map_proj) %&gt;% select(species_observed) both_pts &lt;- list(before_ss = all_pts, after_ss = ss_pts) # map par(mfrow = c(2, 1)) for (i in seq_along(both_pts)) { par(mar = c(0.25, 0.25, 0.25, 0.25)) # set up plot area plot(st_geometry(both_pts[[i]]), col = NA) # contextual gis data plot(ne_land, col = &quot;#dddddd&quot;, border = &quot;#888888&quot;, lwd = 0.5, add = TRUE) plot(bcr, col = &quot;#cccccc&quot;, border = NA, add = TRUE) plot(ne_state_lines, col = &quot;#ffffff&quot;, lwd = 0.75, add = TRUE) plot(ne_country_lines, col = &quot;#ffffff&quot;, lwd = 1.5, add = TRUE) # ebird observations # not observed plot(st_geometry(both_pts[[i]]), pch = 19, cex = 0.1, col = alpha(&quot;#555555&quot;, 0.25), add = TRUE) # observed plot(filter(both_pts[[i]], species_observed) %&gt;% st_geometry(), pch = 19, cex = 0.3, col = alpha(&quot;#4daf4a&quot;, 0.5), add = TRUE) # legend legend(&quot;bottomright&quot;, bty = &quot;n&quot;, col = c(&quot;#555555&quot;, &quot;#4daf4a&quot;), legend = c(&quot;Non-detection&quot;, &quot;Detection&quot;), pch = 19) box() par(new = TRUE, mar = c(0, 0, 3, 0)) if (names(both_pts)[i] == &quot;before_ss&quot;) { title(&quot;Wood Thrush eBird Observations\\nBefore subsampling&quot;) } else { title(&quot;After subsampling&quot;) } } For Wood Thrush, subsampling the detections and non-detections independently is sufficient for dealing with class imbalance; however, for species that are extremely rare, it may be worthwhile retaining all detections or even oversampling detections. 4.4 Random forests Now we’ll use a random forest model to relate detection/non-detection of Wood Thrush to the MODIS habitat covariates, while also accounting for variation in detectability by including a suite of effort covariates. Before we fit the random forest model, we randomly split the data into 80% of checklists for training and 20% for testing. We’ll hold this 20% aside when we fit the model, then use it as an independent data set to test the predictive performance of the model. ebird_split &lt;- ebird_ss %&gt;% # random forests requires an integer repsonse mutate(species_observed = as.integer(species_observed)) %&gt;% # select only the columns to be used in the model select(species_observed, observation_date, time_observations_started, duration_minutes, effort_distance_km, number_observers, contains(&quot;checklist_calibration_index&quot;), starts_with(&quot;pland_&quot;)) %&gt;% drop_na() # split 80/20 ebird_split &lt;- ebird_split %&gt;% split(if_else(runif(nrow(.)) &lt;= 0.8, &quot;train&quot;, &quot;test&quot;)) map_int(ebird_split, nrow) #&gt; test train #&gt; 2075 8316 There are several packages for fitting random forests in R; however, we’ll use ranger, which is a blazingly fast implementation with all the features we need. We fit a model with 1,000 classification trees (num.trees). For the number of variables randomly sampled at each split (mtry), we used the square root of the number of covariates (21). This choice of parameters will be suitable for a broad range of species distribution modeling tasks. # grow random forest rf &lt;- ranger(formula = species_observed ~ ., num.trees = 1000, mtry = sqrt(ncol(ebird_split$train) - 1), importance = &quot;impurity&quot;, data = ebird_split$train) We’ve found that predictions from ranger can be sensitive to the particular checklists that are selection in the spatial subsampling and test/train split steps. To ensure this is not an issue, we suggest running several iterations of this code, using different sets of samples. The random sampling be controlled by trying different values for the ranomd seed set at the start of the chapter with set.seed(1). 4.4.1 Calibration For various reasons, the predicted probabilities from models do not always align with the observed frequencies of detections. For example, examining all sites with an estimated 0.2 probability of encounter, may in reality have an average encounter rate of 0.35 (35% of sites record the species). Where there is a mismatch between estimated and observed encounter rates, model calibration aligns the estimated probabilities to the observed frequencies. For further details on model calibration consult Phillips and Elith (2010). To calibrate our model results, we predict encounter rate for each checklist in the training set, then fit a binomial Generalized Additive Model (GAM) with the real observations as the response and the predicted encounter rate as the predictor variable. We’ll fit the predictor variable using a smooth with four degrees of freedom. To fit the GAM, we’ll use the R package scam so the shape can be constrained to be monotonically increasing. # predict on test partition rf_pred_train &lt;- predict(rf, data = ebird_split$train, type = &quot;response&quot;) rf_pred_train &lt;- tibble(id = seq_along(rf_pred_train$predictions), # actual detection/non-detection obs = ebird_split$train$species_observed, # prediction pred = rf_pred_train$predictions) %&gt;% drop_na() # fit calibration model calibration_model &lt;- scam(obs ~ s(pred, k = 5, bs = &quot;mpi&quot;), data = rf_pred_train, family = binomial) # plot cal_pred &lt;- tibble(pred = seq(0, 1, length.out = 100)) cal_pred &lt;- predict(calibration_model, cal_pred, type = &quot;response&quot;) %&gt;% bind_cols(cal_pred, calibrated = .) ggplot(cal_pred) + aes(x = pred, y = calibrated) + geom_line() + labs(x = &quot;RF prediction&quot;, y = &quot;Calibrated prediction&quot;, title = &quot;Calibration model&quot;) The calibrated random forest model is now the combination of the original random forest model and the calibration model. 4.4.2 Assessment Now we’ll assess the calibrated random forest model with the 20% test dataset. We’ll use a range of performance metrics to compare the predictions to the actual observations: mean squared error (MSE), sensitivity, specificity, AUC, Kappa, and Brier score. Several of these metrics require the raw predicted probabilities to be classified into detection/non-detection. We’ll do this using a threshold, chosen to maximize the Kappa statistic. # predict on test data using calibrated model p_fitted &lt;- predict(rf, data = ebird_split$test, type = &quot;response&quot;) p_calibrated &lt;- predict(calibration_model, newdata = tibble(pred = p_fitted$predictions), type = &quot;response&quot;) rf_pred_test &lt;- data.frame(id = seq_along(p_calibrated), # actual detection/non-detection obs = ebird_split$test$species_observed, # calibrated prediction fit = p_fitted$predictions, # calibrated prediction cal = p_calibrated) %&gt;% drop_na() # mean squared error (mse) mse_fit &lt;- mean((rf_pred_test$obs - rf_pred_test$fit)^2, na.rm = TRUE) mse_cal &lt;- mean((rf_pred_test$obs - rf_pred_test$cal)^2, na.rm = TRUE) # pick threshold to maximize kappa opt_thresh &lt;- optimal.thresholds(rf_pred_test, opt.methods = &quot;MaxKappa&quot;) # calculate accuracy metrics: auc, kappa, sensitivity, specificity, brier metrics_fit &lt;- rf_pred_test %&gt;% select(id, obs, fit) %&gt;% presence.absence.accuracy(threshold = opt_thresh$fit, na.rm = TRUE, st.dev = FALSE) metrics_cal &lt;- rf_pred_test %&gt;% select(id, obs, cal) %&gt;% presence.absence.accuracy(threshold = opt_thresh$cal, na.rm = TRUE, st.dev = FALSE) rf_assessment &lt;- tibble( model = c(&quot;RF&quot;, &quot;Calibrated RF&quot;), mse = c(mse_fit, mse_cal), sensitivity = c(metrics_fit$sensitivity, metrics_cal$sensitivity), specificity = c(metrics_fit$specificity, metrics_cal$specificity), auc = c(metrics_fit$AUC, metrics_cal$AUC), kappa = c(metrics_fit$Kappa, metrics_cal$Kappa), brier = c(brier(rf_pred_test$obs, rf_pred_test$fit)$bs, brier(rf_pred_test$obs, rf_pred_test$cal)$bs) ) model mse sensitivity specificity auc kappa brier RF 0.088 0.552 0.870 0.808 0.342 0.089 Calibrated RF 0.116 0.295 0.944 0.808 0.271 0.109 ** Daniel: can you add something here about the different metrics? ** 4.5 Environmental associations From the random forest model, we can glean two important sources of information about the association between Wood Thrush detection and features of their local environment. First, predictor importance is a measure of the predictive power of each covariate, and is calculated as a byproduct of fitting a random forest model. Second, partial dependence plots estimate the marginal effect of one predictor holding all other predictors constant. 4.5.1 Predictor importance During the process of fitting a random forest model, some variables are removed at each node of the trees that make up the random forest. Predictor importance is based on the mean decrease in accuracy of the model when a given covariate is not used. It’s technically an average Gini index, but essentially larger values indicate that a predictor is more important to the model. pi &lt;- enframe(rf$variable.importance, &quot;predictor&quot;, &quot;importance&quot;) ggplot(pi)+ aes(x = fct_reorder(predictor, importance), y = importance) + geom_col() + geom_hline(yintercept = 0, size = 2, colour = &quot;#555555&quot;) + scale_y_continuous(expand = c(0, 0)) + coord_flip() + labs(x = NULL, y = &quot;Predictor Importance (Gini Index)&quot;, fill = &quot;Predictor Importance (Gini Index)&quot;) + theme_minimal() + theme(panel.grid = element_blank(), panel.grid.major.x = element_line(colour = &quot;#cccccc&quot;, size = 0.5)) The most important predictors of detection/non-detection are generally effort variables. Indeed, that’s the case here: CCI, start time, date, and checklist duration are all important predictors. The top environmetal predictors are the proportion of woody savanna (UMD landcover class 8) and deciduous broadleaf forests (class 4). Note that high importance doesn’t tell us the direction of the relationship with detection, for that we’ll have to look at partial dependence plots. 4.5.2 Partial dependence Partial dependence plots show the marginal effect of a given predictor on encounter rate averaged across the other predictors. These plots are generated by predicting encounter rate at a regular sequence of points across the full range of values of a given predictor. At each predictor value, predictions of encounter rate are made for a random subsample of the training dataset with the focal predictor fixed, but all other predictors left as is. The encounter rate predictions are then averaged across all the checklists in the training dataset giving an estimate of the average encounter rate at a specific value of the focal predictor. Fortunately, the R package edarf has a function to calculate partial dependence from random forest models. Let’s look at partial dependence plots for the most important predictors. # top 9 predictors other than date top_pred &lt;- pi %&gt;% filter(!predictor %in% c(&quot;observation_date&quot;)) %&gt;% top_n(n = 9, wt = importance) # calculate partial dependence for each predictor pd &lt;- top_pred$predictor %&gt;% map_df(~ partial_dependence(rf, .x, data = ebird_split$train) %&gt;% mutate(variable = .x) %&gt;% set_names(c(&quot;value&quot;, &quot;prob_det&quot;, &quot;variable&quot;))) %&gt;% select(variable, value, prob_det) # plot ggplot(pd) + aes(x = value, y = prob_det) + geom_line() + geom_point() + scale_y_continuous(labels = scales::percent) + facet_wrap(~ as_factor(variable), nrow = 3, scales = &quot;free&quot;) + labs(x = NULL, y = &quot;Encounter Rate&quot;) + theme_minimal() + theme_minimal() + theme(panel.grid = element_blank(), axis.line = element_line(color = &quot;grey60&quot;), axis.ticks = element_line(color = &quot;grey60&quot;)) There are a range of interesting responses here. As seen in Section 2.5, the encounter rate for Wood Thrush peaks early in the morning when they’re most likely to be singing, then quickly drops off in the middle of the day, before slightly increasing in the evening. The CCI seems to show a threshold effect; there’s a jump from 10% to 30% encounter rate around a CCI of 2. Wood Thrush can be hard to see, but have a prominent and distinctive call, emblematic of North America’s eastern hardwood forest, and perhaps less experienced birders aren’t able to recognize this call. Some other predictors show a more smoothly increasing relationship with encounter rate, for example, as the landscape contains more deciduous forest (pland_04), the encounter rate increases. 4.6 Prediction Now for the fun part: let’s use the calibrated random forest model to make a map of Wood Thrush encounter rate in BCR 27! In Section 3.4, we created a prediction surface consisting of the PLAND habitat covariates summarized on a regular grid of points across BCR 27. In this section, we’ll make predictions of encounter rate at these points. However, first we need to bring effort variables into this prediction surface. We’ll make predictions for a standard eBird checklist: a 1 km, 1 hour traveling count done by a single expert eBirder (CCI = 2) at the peak time of day for detecting this species. Finally, we’ll make these predictions for June 15, 2017, the middle of our June focal window for the latest year for which MODIS landcover data exist. To find the time of day with the highest detection probability, we can look for the peak of the partial dependence plot. The one caveat to this approach is that it’s important we focus on time of day for which there are enough data to make predictions. In particular, when there is an increasing trend in detectability as observations start earlier in the morning and few checklists late at night, the model may incorrectly extrapolate that trend to show highest detectability at night. Let’s start by looking at a plot to see if this is happening here. # find peak time of day from partial dependence pd_time &lt;- partial_dependence(rf, vars = &quot;time_observations_started&quot;, # make estimates at 10 minute intervals # use the entire training dataset for estimation n = c(24 * 6, nrow(ebird_split$train)), data = ebird_split$train) #&gt; Predicting.. Progress: 98%. Estimated remaining time: 0 seconds. #&gt; Aggregating predictions.. Progress: 98%. Estimated remaining time: 0 seconds. # histogram g_hist &lt;- ggplot(ebird_split$train) + aes(x = time_observations_started) + geom_histogram(binwidth = 1, center = 0.5, color = &quot;grey30&quot;, fill = &quot;grey50&quot;) + scale_x_continuous(breaks = seq(0, 24, by = 3)) + scale_y_continuous(labels = scales::comma) + labs(x = &quot;Hours since midnight&quot;, y = &quot;# checklists&quot;, title = &quot;Distribution of observation start times&quot;) # gam g_pd &lt;- ggplot(pd_time) + aes(x = time_observations_started, y = species_observed) + geom_line() + scale_x_continuous(breaks = seq(0, 24, by = 3)) + labs(x = &quot;Hours since midnight&quot;, y = &quot;Probability of reporting&quot;, title = &quot;Observation start time partial dependence&quot;) # combine grid.arrange(g_hist, g_pd) As expected, the peak of detectibility is occurring at start times near midnight, which is an artifact of the low data density at night. Let’s instead look for the peak time within hours of the day that contain at least 1% of the training data. # hours with at least 1% of checklists search_hours &lt;- ebird_split$train %&gt;% mutate(hour = floor(time_observations_started)) %&gt;% count(hour) %&gt;% mutate(pct = n / sum(n)) %&gt;% filter(pct &gt;= 0.01) # constrained peak time t_peak &lt;- pd_time %&gt;% filter(floor(time_observations_started) %in% search_hours$hour) %&gt;% top_n(1, wt = desc(time_observations_started)) %&gt;% pull(time_observations_started) Based on this analysis, the best time for viewing Wood Thrush is at 5:09 AM. Now we can add the effort variables to the prediction surface. # add effort covariates to prediction pred_surface_eff &lt;- pred_surface %&gt;% mutate(observation_date = ymd(&quot;2016-06-15&quot;), time_observations_started = t_peak, duration_minutes = 60, effort_distance_km = 1, number_observers = 1, checklist_calibration_index = 2) # predict pred_rf &lt;- predict(rf, data = pred_surface_eff, type = &quot;response&quot;) # apply calibration models pred_rf_cal &lt;- predict(calibration_model, data.frame(pred = pred_rf$predictions), type = &quot;response&quot;) # add to prediction surface pred_er &lt;- bind_cols(pred_surface_eff, encounter_rate = pred_rf_cal) %&gt;% select(latitude, longitude, encounter_rate) Next, we’ll convert this data frame to spatial points using sf, then rasterize the points using the prediction surface raster template. r_pred &lt;- pred_er %&gt;% st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) %&gt;% st_transform(crs = projection(r)) %&gt;% rasterize(r) r_pred &lt;- r_pred[[-1]] # save the raster writeRaster(r_pred, &quot;output/rf-model_encounter-rate_woothr.tif&quot;, overwrite = TRUE) Finally, we can map these predictions! # project predictions r_pred_proj &lt;- projectRaster(r_pred, crs = map_proj$proj4string, method = &quot;ngb&quot;) par(mar = c(3.5, 0.25, 0.25, 0.25)) # set up plot area plot(bcr, col = NA, border = NA) plot(ne_land, col = &quot;#dddddd&quot;, border = &quot;#888888&quot;, lwd = 0.5, add = TRUE) # modified plasma palette plasma_rev &lt;- rev(plasma(25, end = 0.9)) gray_int &lt;- colorRampPalette(c(&quot;#dddddd&quot;, plasma_rev[1])) pal &lt;- c(gray_int(4)[2], plasma_rev) # encounter rate mx &lt;- ceiling(1000 * cellStats(r_pred_proj, max)) / 1000 brks &lt;- seq(0, mx, length.out = length(pal) + 1) plot(r_pred_proj, col = pal, breaks = brks, maxpixels = ncell(r_pred_proj), legend = FALSE, add = TRUE) # borders plot(bcr, border = &quot;#000000&quot;, col = NA, lwd = 1, add = TRUE) plot(ne_state_lines, col = &quot;#ffffff&quot;, lwd = 0.75, add = TRUE) plot(ne_country_lines, col = &quot;#ffffff&quot;, lwd = 1.5, add = TRUE) box() # legend par(new = TRUE, mar = c(0, 0, 0, 0)) title &lt;- &quot;Wood Thrush Encounter Rate&quot; lbl_brks &lt;- seq(0, mx, by = 0.1) image.plot(zlim = range(brks), legend.only = TRUE, col = pal, smallplot = c(0.25, 0.75, 0.06, 0.09), horizontal = TRUE, axis.args = list(at = lbl_brks, labels = lbl_brks, fg = &quot;black&quot;, col.axis = &quot;black&quot;, cex.axis = 0.75, lwd.ticks = 0.5, padj = -1.5), legend.args = list(text = title, side = 3, col = &quot;black&quot;, cex = 1, line = 0)) References "],
["occupancy.html", "Chapter 5 Modeling Occupancy 5.1 Introduction 5.2 Data preparation 5.3 Spatial subsampling 5.4 Occupancy modeling 5.5 Prediction", " Chapter 5 Modeling Occupancy 5.1 Introduction In this chapter, we’ll cover basic steps for estimating occupancy probability using data from eBird. In Chapter 4, we used analytical approaches that modeled variation in detectability by inclduing covariates that are known to influence detection rates (e.g. effort). In contrast, occupancy models jointly model the ecological process of species occurrence and the observation process of species detection. The aplication of these models typically requires repeated visits to a single site during a relatively short time frame, over which the population can be considered as closed. However, it is possible to impose this repeat visit structure on eBird data to generate a subset of data suitable for estimating occupancy. Here, we discuss how to process eBird observations to meet existing criteria for the application of occupancy models. To illustrate our example, we apply single-season occupancy models to estimate occupancy and detection probabilities of Wood Thrush for the month of June in BCR 27. This chapter is distinct from the previous chapter on modeling encounter rate in two important ways. First, the random forest model used in Chapter 4 is an example of a machine learning approach, while the occupancy models used in this chapter are a more traditional likelihood approach. This latter type of stastitical approach is best suited for addressing specific questions and hypotheses, while the goal of machine learning is primarily to identify patterns and make predictions (Bzdok, Altman, and Krzywinski 2018). Second, machine learning approaches can accomodate complex interactions between covariates and non-linear effects, often needed to model habitat associations that can vary across large spaial and temporal scales. In contrast, occupancy models are more suitable for exploring linear effects and simpler interactions. In this example, we specifically focus on the mechanics of filtering and formatting the data to fit occupancy models, and less on how to choose which predictors to include for detection and occupancy probabilities. The predictors we do include are informed by our inferences on variable from the random forest model in Chapter 4. If you worked through the previous chapters, you should have all the data necessary for this chapter. You can also download the data package, and unzip it to your working directory. Note that the Checklist Calibration Index (CCI), which calibrates observers and checklists against others from similar times and places, is an optional covariate in these models. Including CCI typical leads to marked improvement in model performance; however, due to the sensitive nature of these data you will need to download them separately after you agree to the terms and conditions. If you’ve downloaded these data, put the CCI text file in the data/ subdirectory of your project. library(auk) library(lubridate) library(sf) library(dggridR) library(unmarked) library(raster) library(viridis) library(MuMIn) library(AICcmodavg) library(fields) library(tidyverse) # resolve namespace conflicts select &lt;- dplyr::select projection &lt;- raster::projection set.seed(1) # ebird data ebird &lt;- read_csv(&quot;data/ebd_woothr_june_bcr27_zf.csv&quot;) %&gt;% mutate(year = year(observation_date), # occupancy modeling requires an integer response species_observed = as.integer(species_observed)) # modis habitat covariates habitat &lt;- read_csv(&quot;data/modis_pland_location-year.csv&quot;) %&gt;% mutate(year = as.integer(year)) # combine ebird and habitat data ebird_habitat &lt;- inner_join(ebird, habitat, by = c(&quot;locality_id&quot;, &quot;year&quot;)) # optional checklist calibration index cci_file &lt;- &quot;data/cci_june_bcr27.csv&quot; if (file.exists(cci_file)) { cci &lt;- read_csv(&quot;data/cci_june_bcr27.csv&quot;) ebird_habitat &lt;- inner_join(ebird_habitat, cci, by = &quot;checklist_id&quot;) %&gt;% filter(!is.na(checklist_calibration_index)) } # prediction surface pred_surface &lt;- read_csv(&quot;data/modis_pland_prediction-surface.csv&quot;) r &lt;- raster(&quot;data/prediction-surface.tif&quot;) # load gis data for making maps map_proj &lt;- st_crs(102003) ne_land &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_land&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() bcr &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;bcr&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_country_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_country_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_state_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_state_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() 5.2 Data preparation First, we need to extract a subset of the eBird data suitable for occupancy modeling, then perform spatiotemporal subsampling to deal with bias in the data. Let’s start by filtering our data to include only checklists with 5 or fewer observers, since there are very few observations with more than 5 observers. ebird_filtered &lt;- filter(ebird_habitat, number_observers &lt;= 5) In some situations, you may want to further filter the data based on the results of an exploratory analysis similar to the one conducted in Section @ref{ebird-explore}. However, for the purpose of comparing results among different modeling approaches and best practices, we won’t further filter the observations in eBird for our occupancy example. 5.2.1 Data formatting Now, we can generate detection histories for each location we define as a site. In this example, we define the month of June as the time period that we assume that the population is closed for Wood Thrush, and a site is defined as a location (latitude/longitude) that is visited at least twice by the same observer within our defined period of closure (i.e. the smonth of June). The auk function filter_repeat_visits() is designed to extract a subset of eBird data suitable for occupancy modeling. We first filter the data to only sites that have at least 2 visits (min_obs). We then define the maximum length of our detection history (max_obs) as 10 visits or checklists. When a specific site has been visited more than 10 times, the function will randomly select 10 checklists from the total number of visits. Since we only have data from June, using annual_closure = TRUE defines the temporal period of closure as the whole month of June for a given primary sampling period (i.e. year). Finally, site_vars specifies the set of variables that defines a site. In this example, a site is defined jointly by location and observer IDs. occ &lt;- filter_repeat_visits(ebird_filtered, min_obs = 2, max_obs = 10, annual_closure = TRUE, date_var = &quot;observation_date&quot;, site_vars = c(&quot;locality_id&quot;, &quot;observer_id&quot;)) # entire data set nrow(ebird_habitat) #&gt; [1] 40477 # reduced data set nrow(occ) #&gt; [1] 14428 # how many individual sites there are n_distinct(occ$site) #&gt; [1] 4167 Three new variables are added to the dataset by filter_repeat_visits(): site is a unique site ID, closure_id identifies the primary period of closure (in this case the year), and n_observations is the number of visits to each site. Our data is now formatted and ready to be analyzed using occupancy models. Note that we’ve made a tradeoff in sample size, dropping from 40,059 checklists to 14,428 checklists over 4,167 sites. We’ll fit single-season occupancy models using the unmarked R package. For further details on the type of data format required for this package, consult the documentation for the unmarked function formatWide(). The auk function format_unmarked_occu() converts data from a vertical format in which each row is an observation (e.g. as in the EBD) to a horizontal detection history required by unmarked, where each row is a site. At this stage, we need to specify which variables will be site-level covariates and which will be observation-level covariates. Covariates for each site are specific to each primary sampling period of closure (e.g. month of June), and will influence the ecological process of species occurrence. Covariates collected during each sampling occasion (i.e. checklist) are those that are specific to each sampling occasion and will influence the observational process, or detection probability. For this example, we’ll use MODIS habitat variables as covariates for modeling the occupancy probability of Wood Thrush. Based on variable importance measures from Chapter 4, we include deciduous broadleaf forest (pland_04) and mixed forest (pland_05) as habitat types for which we expect positive relationships with occupancy, and croplands (pland_12) and urban (pland_13), for which we expect negative relationships. For detection probability, we include six variables related to effort and the detection process, as well as deciduous broadleaf forest (pland_04) and mixed forest (pland_05). # if cci is available, use it as an observation covariate obs_covs &lt;- c(&quot;time_observations_started&quot;, &quot;duration_minutes&quot;, &quot;effort_distance_km&quot;, &quot;number_observers&quot;, &quot;protocol_type&quot;, &quot;pland_04&quot;, &quot;pland_05&quot;) if (&quot;checklist_calibration_index&quot; %in% names(occ)) { obs_covs &lt;- c(obs_covs, &quot;checklist_calibration_index&quot;) } # format for unmarked occ_wide &lt;- format_unmarked_occu(occ, site_id = &quot;site&quot;, response = &quot;species_observed&quot;, site_covs = c(&quot;n_observations&quot;, &quot;latitude&quot;, &quot;longitude&quot;, # % deciduous forest &quot;pland_04&quot;, # % mixed forest &quot;pland_05&quot;, # % cropland &quot;pland_12&quot;, # % urban &quot;pland_13&quot;), obs_covs = obs_covs) 5.3 Spatial subsampling As discussed in Section 4.3, spatial subsampling eBird observations reduces spatial bias. We’ll use the same hexagonal subsampling approach as in Chapter 4; however, here we’ll subsample at the level of sites rather than observations. # generate hexagonal grid with ~ 5 km betweeen cells dggs &lt;- dgconstruct(spacing = 5) # get hexagonal cell id for each site occ_wide_cell &lt;- occ_wide %&gt;% mutate(cell = dgGEO_to_SEQNUM(dggs, longitude, latitude)$seqnum) # sample one checklist per grid cell occ_ss &lt;- occ_wide_cell %&gt;% group_by(cell) %&gt;% sample_n(size = 1) %&gt;% ungroup() %&gt;% select(-cell) This resulted in a 69.0% decrease in the number of sites. 5.3.1 unmarked object Finally, we’ll convert this dataframe of observations into an unmarked object, which is required for fitting occupancy models. occ_um &lt;- formatWide(occ_ss, type = &quot;unmarkedFrameOccu&quot;) summary(occ_um) #&gt; unmarkedFrame Object #&gt; #&gt; 1290 sites #&gt; Maximum number of observations per site: 10 #&gt; Mean number of observations per site: 3.18 #&gt; Sites with at least one detection: 141 #&gt; #&gt; Tabulation of y observations: #&gt; 0 1 &lt;NA&gt; #&gt; 3875 231 8794 #&gt; #&gt; Site-level covariates: #&gt; n_observations latitude longitude pland_04 #&gt; Min. : 2.00 Min. :29.4 Min. :-91.4 Min. :0.000 #&gt; 1st Qu.: 2.00 1st Qu.:31.0 1st Qu.:-86.1 1st Qu.:0.000 #&gt; Median : 2.00 Median :32.7 Median :-81.7 Median :0.000 #&gt; Mean : 3.18 Mean :33.2 Mean :-82.3 Mean :0.067 #&gt; 3rd Qu.: 3.00 3rd Qu.:35.1 3rd Qu.:-78.3 3rd Qu.:0.040 #&gt; Max. :10.00 Max. :38.3 Max. :-75.5 Max. :1.000 #&gt; pland_05 pland_12 pland_13 #&gt; Min. :0.000 Min. :0.000 Min. :0.000 #&gt; 1st Qu.:0.000 1st Qu.:0.000 1st Qu.:0.000 #&gt; Median :0.000 Median :0.000 Median :0.000 #&gt; Mean :0.051 Mean :0.037 Mean :0.112 #&gt; 3rd Qu.:0.000 3rd Qu.:0.000 3rd Qu.:0.080 #&gt; Max. :0.960 Max. :1.000 Max. :1.000 #&gt; #&gt; Observation-level covariates: #&gt; time_observations_started duration_minutes effort_distance_km #&gt; Min. : 0 Min. : 1 Min. :0 #&gt; 1st Qu.: 8 1st Qu.: 15 1st Qu.:0 #&gt; Median :10 Median : 31 Median :0 #&gt; Mean :12 Mean : 52 Mean :1 #&gt; 3rd Qu.:16 3rd Qu.: 68 3rd Qu.:1 #&gt; Max. :24 Max. :300 Max. :5 #&gt; NA&#39;s :8794 NA&#39;s :8794 NA&#39;s :8794 #&gt; number_observers protocol_type pland_04 pland_05 #&gt; Min. :1 Length:12900 Min. :0 Min. :0 #&gt; 1st Qu.:1 Class :character 1st Qu.:0 1st Qu.:0 #&gt; Median :1 Mode :character Median :0 Median :0 #&gt; Mean :1 Mean :0 Mean :0 #&gt; 3rd Qu.:1 3rd Qu.:0 3rd Qu.:0 #&gt; Max. :5 Max. :1 Max. :1 #&gt; NA&#39;s :8794 NA&#39;s :8794 NA&#39;s :8794 #&gt; checklist_calibration_index #&gt; Min. :-4 #&gt; 1st Qu.:-1 #&gt; Median : 0 #&gt; Mean : 0 #&gt; 3rd Qu.: 1 #&gt; Max. : 2 #&gt; NA&#39;s :8794 5.4 Occupancy modeling Now that we have created a data frame with detection histories and covariates, we can use unmarked to fit a single-season occupancy model. In this book, we won’t delve into the mechanics of occupacy models; however, there is a rich literature on occupancy modeling and readers wishing to learn more about this field may want to consult the book on the topic by MacKenzie et al. (2017). Here we simply fit a single-season occupancy model to our data using the occu() function, specifying the detection and occupancy covariates, respectively, via a double right-hand sided formula of the form ~ detection covariates ~ occupancy covariates. # use cci in model formula if available if (&quot;checklist_calibration_index&quot; %in% names(occ_um@obsCovs)) { mod_formula &lt;- ~ time_observations_started + duration_minutes + effort_distance_km + number_observers + protocol_type + checklist_calibration_index + pland_04 + pland_05 ~ pland_04 + pland_05 + pland_12 + pland_13 } else { mod_formula &lt;- ~ time_observations_started + duration_minutes + effort_distance_km + number_observers + protocol_type + pland_04 + pland_05 ~ pland_04 + pland_05 + pland_12 + pland_13 } # fit model occ_model &lt;- occu(mod_formula, data = occ_um) # look at the regression coefficients from the models summary(occ_model) #&gt; #&gt; Call: #&gt; occu(formula = mod_formula, data = occ_um) #&gt; #&gt; Occupancy (logit-scale): #&gt; Estimate SE z P(&gt;|z|) #&gt; (Intercept) -1.802 0.179 -10.049 9.24e-24 #&gt; pland_04 2.407 0.778 3.094 1.97e-03 #&gt; pland_05 6.289 1.585 3.968 7.25e-05 #&gt; pland_12 0.246 0.768 0.321 7.48e-01 #&gt; pland_13 -1.337 0.670 -1.996 4.59e-02 #&gt; #&gt; Detection (logit-scale): #&gt; Estimate SE z P(&gt;|z|) #&gt; (Intercept) -1.66684 0.39480 -4.2220 2.42e-05 #&gt; time_observations_started -0.04350 0.02069 -2.1024 3.55e-02 #&gt; duration_minutes 0.00899 0.00199 4.5181 6.24e-06 #&gt; effort_distance_km -0.00562 0.09708 -0.0579 9.54e-01 #&gt; number_observers 0.26518 0.16853 1.5735 1.16e-01 #&gt; protocol_typeTraveling 0.67222 0.25619 2.6239 8.69e-03 #&gt; checklist_calibration_index 0.58500 0.12483 4.6865 2.78e-06 #&gt; pland_04 -0.16888 0.59161 -0.2855 7.75e-01 #&gt; pland_05 -1.10098 0.52040 -2.1156 3.44e-02 #&gt; #&gt; AIC: 1338 #&gt; Number of sites: 1290 #&gt; optim convergence code: 0 #&gt; optim iterations: 80 #&gt; Bootstrap iterations: 0 5.4.1 Assessment Occupancy models assume that at at least one model in the set provides an adequate fit to the data. Although few goodness of fit tests exist for occupancy models, we include a section on how to perform the MacKenzie and Bailey (2004) goodness-of-fit test. This approach calculates a Pearson’s chi-square fit statistic to the observed and expected frequencies of detection histories for a given model. For this example, we used the mb.gof.test() test function in the AICcmodavg package, which can handle occupancy models produced by the occu() function in unmarked, to calculate the observed and expected frequencies of detection histories. Note that this process requires simulating a large number of bootstrap samples (1,000 here) and takes a long time to run. You may want to skip this section or reduce nsim to a much smaller number (e.g. 10) in the interest of speed. However, when applying this in practice, you should run the test with the full number of simulations to get accurate results. occ_gof &lt;- mb.gof.test(occ_model, nsim = 1000, plot.hist = FALSE) print(occ_gof) #&gt; #&gt; MacKenzie and Bailey goodness-of-fit for single-season occupancy model #&gt; #&gt; Chi-square statistic = 1987 #&gt; Number of bootstrap samples = 1000 #&gt; P-value = 0.324 #&gt; #&gt; Quantiles of bootstrapped statistics: #&gt; 0% 25% 50% 75% 100% #&gt; 330 1256 1661 2199 49998 #&gt; #&gt; Estimate of c-hat = 0.97 For this example, the probabilitty of getting the calculated Chi-square statistic under a null sampling distribution is indicated by the P-value of 0.324, indicating that there is no reason to consider a lack of fit (P-value &gt; 0.1). In addition, we also get an estimate of the overdisperson parameter (c-hat) for the model by dividing the observed chi-square statistic by the mean of the statistics obtained from simulation. In this example, c-hat = 0.97, which is very close to c-hat = 1, indicating that the variance is not greater than the mean, and that there is no evidence for overdispersion. 5.4.2 Model selection Next, we use a model selection approach to compare and rank our candidate model set. For this example, we use the dredge() function to explore a candidate set consisting of all possible additive combinations of the gobal model. However, we suggest that a more thoughtful approach be considered for specific applications and different types of predictor variables. # dredge candidate model set occ_dredge &lt;- dredge(occ_model) # model comparison select(occ_dredge, df, logLik, AICc, delta, weight) #&gt; df logLik AICc delta weight #&gt; 12 13 -655 1337 0.00 5.90e-01 #&gt; 16 14 -655 1339 1.94 2.24e-01 #&gt; 4 12 -658 1340 3.06 1.28e-01 #&gt; 8 13 -658 1341 4.73 5.56e-02 #&gt; 11 12 -662 1348 11.62 1.77e-03 #&gt; 15 13 -662 1350 13.65 6.42e-04 #&gt; 3 11 -666 1355 18.03 7.18e-05 #&gt; 7 12 -666 1357 20.03 2.65e-05 #&gt; 10 12 -670 1365 28.03 4.84e-07 #&gt; 14 13 -670 1367 30.03 1.78e-07 #&gt; 2 11 -676 1374 36.97 5.53e-09 #&gt; 6 12 -676 1376 38.97 2.04e-09 #&gt; 9 11 -678 1379 41.99 4.50e-10 #&gt; 13 12 -678 1380 43.54 2.07e-10 #&gt; 1 10 -687 1394 56.88 2.62e-13 #&gt; 5 11 -687 1396 58.83 9.92e-14 A quick look at the dredge object reveals that there is not a clear model, or even set of models, that are most likely to have generated our data. This is evident from the low AIC weight for the model with the lowest AICc value. Given this, and the fact that all of our effects are linear and use the same family and link function, we’ll average across all models, weighted by AICc, to produce a final model that we’ll use for prediction. However, there may be scenarios in which there is a clear set of high performing models, in which case you can use the get.models() funciton to extract just these models prior to averaging. # average models based on model weights occ_avg &lt;- model.avg(occ_dredge, fit = TRUE) # model coefficients t(occ_avg$coefficients) #&gt; full subset #&gt; psi(Int) -1.81851 -1.81851 #&gt; psi(pland_04) 2.43398 2.44010 #&gt; psi(pland_05) 6.38399 6.38400 #&gt; psi(pland_13) -1.10658 -1.35544 #&gt; p(Int) -1.67222 -1.67222 #&gt; p(checklist_calibration_index) 0.58865 0.58865 #&gt; p(duration_minutes) 0.00896 0.00896 #&gt; p(effort_distance_km) -0.00451 -0.00451 #&gt; p(number_observers) 0.26783 0.26783 #&gt; p(pland_04) -0.16929 -0.16929 #&gt; p(pland_05) -1.11056 -1.11056 #&gt; p(protocol_typeTraveling) 0.67231 0.67231 #&gt; p(time_observations_started) -0.04339 -0.04339 #&gt; psi(pland_12) 0.08141 0.29096 5.5 Prediction In this section, we’ll estimate the distribution of Wood Thrush in BCR 27. Similar to Section 3.4, we’ll generate a prediction surface using the PLAND habitat covariates summarized on a regular grid of points across BCR 27. For this, we’ll use the predict() function to estimate occupancy probabilities, standard errors, and confidence intervals. Recall that when we predicted encouter rate, we had to include effort variables in our prediction surface. We don’t need to do that here because the occupancy submodel doesn’t depend on the effort covariates, these only occur in the detection submodel. occ_pred &lt;- predict(occ_avg, newdata = as.data.frame(pred_surface), type = &quot;state&quot;) # add to prediction surface pred_occ &lt;- bind_cols(pred_surface, occ_prob = occ_pred$fit, occ_se = occ_pred$se.fit) %&gt;% select(latitude, longitude, occ_prob, occ_se) Next, we’ll convert this data frame to spatial points using sf, then rasterize the points using the prediction surface raster template. r_pred &lt;- pred_occ %&gt;% st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) %&gt;% st_transform(crs = projection(r)) %&gt;% rasterize(r) r_pred &lt;- r_pred[[c(&quot;occ_prob&quot;, &quot;occ_se&quot;)]] # save the raster writeRaster(r_pred[[&quot;occ_prob&quot;]], filename = &quot;output/woothr_occupancy-model_prob.tif&quot;, overwrite = TRUE) writeRaster(r_pred[[&quot;occ_se&quot;]], filename = &quot;output/woothr_occupancy-model_se.tif&quot;, overwrite = TRUE) Finally, we can map these predictions! # project predictions r_pred_proj &lt;- projectRaster(r_pred, crs = map_proj$proj4string, method = &quot;ngb&quot;) par(mfrow = c(2, 1)) for (nm in names(r_pred)) { r_plot &lt;- r_pred_proj[[nm]] par(mar = c(3.5, 0.25, 0.25, 0.25)) # set up plot area plot(bcr, col = NA, border = NA) plot(ne_land, col = &quot;#dddddd&quot;, border = &quot;#888888&quot;, lwd = 0.5, add = TRUE) # modified plasma palette plasma_rev &lt;- rev(plasma(25, end = 0.9)) gray_int &lt;- colorRampPalette(c(&quot;#dddddd&quot;, plasma_rev[1])) pal &lt;- c(gray_int(4)[2], plasma_rev) # occupancy mx &lt;- ceiling(1000 * cellStats(r_plot, max)) / 1000 brks &lt;- seq(0, mx, length.out = length(pal) + 1) plot(r_plot, col = pal, breaks = brks, maxpixels = ncell(r_plot), legend = FALSE, add = TRUE) # borders plot(bcr, border = &quot;#000000&quot;, col = NA, lwd = 1, add = TRUE) plot(ne_state_lines, col = &quot;#ffffff&quot;, lwd = 0.75, add = TRUE) plot(ne_country_lines, col = &quot;#ffffff&quot;, lwd = 1.5, add = TRUE) box() # legend par(new = TRUE, mar = c(0, 0, 0, 0)) if (nm == &quot;occ_prob&quot;) { title &lt;- &quot;Wood Thrush Occupancy Probability&quot; lbl_brks &lt;- seq(0, mx, by = 0.1) } else { lbl_brks &lt;- seq(0, mx, by = 0.02) title &lt;- &quot;Wood Thrush Occupancy Uncertainty (SE)&quot; } image.plot(zlim = range(brks), legend.only = TRUE, col = pal, smallplot = c(0.25, 0.75, 0.06, 0.09), horizontal = TRUE, axis.args = list(at = lbl_brks, labels = lbl_brks, fg = &quot;black&quot;, col.axis = &quot;black&quot;, cex.axis = 0.75, lwd.ticks = 0.5, padj = -1.5), legend.args = list(text = title, side = 3, col = &quot;black&quot;, cex = 1, line = 0)) } References "],
["abundance.html", "Chapter 6 Modeling Relative Abundance 6.1 Introduction 6.2 Data preparation 6.3 Abundance models 6.4 Prediction", " Chapter 6 Modeling Relative Abundance 6.1 Introduction The previous two chapters focused on modeling occurrence. In Chapter 4, we modeled encounter rate (i.e. relative occupancy), then in Chapter 5 we modeled absolute occupancy, by explicitly accounting for detection probability. However, in addition to recording which species they observed, most eBirders also specify how many individuals of each species were observed. So, in this chapter, we’ll take advantage of these counts to model relative abundance. The metric we are modelling for each species is the expected number of individuals observed by an expert eBirder on a standard eBird checklist. Note that, as with encounter rate, because we’re not explicitly modeling the detection process, our estimates of abundance will be relative to absolute abundance. We’ll start by reading in the data and spatiotemporally subsampling it to reduce bias. Next, we’ll fit models of relative abundance using Generalized Additive Models (GAM) with count as the response. We’ll test three different distributions for error distribution of the response: zero-inflated Poisson, negative binomial, and Tweedie. The distribution of counts varies by species, season, and region, so it is difficult to predict which statistical distribution will be most appropriate. Running models with three different error distributions gives us the opportunity to assess which of these fit the data best. We’ll use cross-validation to assess the performance of these models and help us choose which of the three is most suitable. Finally, we’ll make predictions of relative abundance throughout BCR 27 and produce a map of these predictions. 6.2 Data preparation Let’s start by loading the necessary packages and data. If you haven’t already done so, you may want to download the data package and unzip it to your working directory. As in previous chapters, the Checklist Calibration Index (CCI) is an optional covariate in these models. If you’ve downloaded these data, put the CCI text file in the data/ subdirectory of your project. If you haven’t downloaded these data, you can proceed with all the other code, but your maps may have some differences to those shown here. Because we’re modeling abundance in this chapter, we’ll remove any records for which the observer reported that Wood Thrush was present, but didn’t report a count of the number of species (coded as ‘X’ records in the eBird database). We’ll also add a day of year variable (1-365) that will be useful as a covariate in the abundance models. library(lubridate) library(sf) library(raster) library(dggridR) library(pdp) library(edarf) library(mgcv) library(fitdistrplus) library(viridis) library(fields) library(tidyverse) # resolve namespace conflicts select &lt;- dplyr::select map &lt;- purrr::map projection &lt;- raster::projection set.seed(1) # ebird data ebird &lt;- read_csv(&quot;data/ebd_woothr_june_bcr27_zf.csv&quot;) %&gt;% mutate(year = year(observation_date), day_of_year = yday(observation_date), protocol_type = factor(protocol_type, levels = c(&quot;Stationary&quot; , &quot;Traveling&quot;))) %&gt;% # remove observations with no count filter(!is.na(observation_count)) # modis habitat covariates habitat &lt;- read_csv(&quot;data/modis_pland_location-year.csv&quot;) %&gt;% mutate(year = as.integer(year)) # combine ebird and habitat data ebird_habitat &lt;- inner_join(ebird, habitat, by = c(&quot;locality_id&quot;, &quot;year&quot;)) # optional checklist calibration index cci_file &lt;- &quot;data/cci_june_bcr27.csv&quot; if (file.exists(cci_file)) { cci &lt;- read_csv(cci_file) ebird_habitat &lt;- inner_join(ebird_habitat, cci, by = &quot;checklist_id&quot;) %&gt;% filter(!is.na(checklist_calibration_index)) } # prediction surface pred_surface &lt;- read_csv(&quot;data/modis_pland_prediction-surface.csv&quot;) r &lt;- raster(&quot;data/prediction-surface.tif&quot;) # load gis data for making maps map_proj &lt;- st_crs(102003) ne_land &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_land&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() bcr &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;bcr&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_country_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_country_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() ne_state_lines &lt;- read_sf(&quot;data/gis-data.gpkg&quot;, &quot;ne_state_lines&quot;) %&gt;% st_transform(crs = map_proj) %&gt;% st_geometry() 6.2.1 Spatiotemporal subsampling As discussed in Section 4.3, spatiotemporal subsampling detection and non-detection observations reduces spatial and temporal bias and the class imbalance. We’ll use exactly the same hexagonal subsampling approach as in Chapter 4. # generate hexagonal grid with ~ 5 km betweeen cells dggs &lt;- dgconstruct(spacing = 5) # get hexagonal cell id and week number for each checklist checklist_cell &lt;- ebird_habitat %&gt;% mutate(cell = dgGEO_to_SEQNUM(dggs, longitude, latitude)$seqnum, week = week(observation_date)) # sample one checklist per grid cell per week # sample detection/non-detection independently ebird_ss &lt;- checklist_cell %&gt;% group_by(species_observed, week, cell) %&gt;% sample_n(size = 1) %&gt;% ungroup() %&gt;% select(-cell, -week) 6.2.2 Test-train split Before we fit the abundance models, we randomly split the data into 80% of checklists for training and 20% for testing. We’ll hold this 20% aside when we fit the model, then use it as an independent data set to test the predictive performance of the model. Here we select a random 20% of the data, but there are a variety of strategies to select data for testing that may be appropriate in different situations. At this stage, we’ll also select only the variables that we’ll use as covariates in the models. In particular, we’ll use the full suite of effort covariates and the same four habitat covariates we used in Chapter 5. Known wood thrush nesting habitats are deciduous broadleaf forest (pland_04) and mixed forest (pland_05). Habitats they are thought to avoid are croplands (pland_12) and urban (pland_13). The specific set of habit covariates you use will be specific for your species and should be informed by a priori ecological knowledge of the species. See Section 3.1 for a list of the habitat covariates available here. hab_covs &lt;- c( # % deciduous forest &quot;pland_04&quot;, # % mixed forest &quot;pland_05&quot;, # % cropland &quot;pland_12&quot;, # % urban &quot;pland_13&quot;) ebird_split &lt;- ebird_ss %&gt;% # select only the columns to be used in the model select(observation_count, # effort covariates day_of_year, time_observations_started, duration_minutes, effort_distance_km, number_observers, protocol_type, contains(&quot;checklist_calibration_index&quot;), # habitat covariates hab_covs) # split 80/20 ebird_split &lt;- ebird_split %&gt;% split(if_else(runif(nrow(.)) &lt;= 0.8, &quot;train&quot;, &quot;test&quot;)) map_int(ebird_split, nrow) #&gt; test train #&gt; 2072 8309 6.3 Abundance models Before we embark on modelling the counts, we’ll start by examining the distribution of the count data. This will give us an idea of which distributions may be appropriate for modeling the counts of this species. We’re looking to assess whether the data fall neatly into known distributions and whether they show evidence of zero-inflation. We look at the distribution of counts both with all the zeros and without the zeros. eBird data often have a very high number of zero counts, as even common bird species are not seen on every checklist. The skewness and kurtosis describe aspects of the shape of distributions. A Cullen &amp; Frey graph shows the possible ranges of skewness and kurtosis for a variety of distributions. These plots show where the species count data fall in relation to a variety of distributions. This indicates which distributions may be most appropriate. By also examining the distribution for just the counts (without zeros), we get an indication of whether a zero-inflated distribution may be appropriate. par(mfrow = c(2, 2)) # counts with zeros hist(ebird_ss$observation_count, main = &quot;Histogram of counts&quot;) descdist(ebird_ss$observation_count, discrete = TRUE) #&gt; summary statistics #&gt; ------ #&gt; min: 0 max: 21 #&gt; median: 0 #&gt; mean: 0.175 #&gt; estimated sd: 0.657 #&gt; estimated skewness: 8.89 #&gt; estimated kurtosis: 163 # counts without zeros pos_counts &lt;- keep(ebird_ss$observation_count, ~ . &gt; 0) hist(pos_counts, main = &quot;Histogram of counts &gt; 0&quot;) descdist(pos_counts, discrete = TRUE) #&gt; summary statistics #&gt; ------ #&gt; min: 1 max: 21 #&gt; median: 1 #&gt; mean: 1.54 #&gt; estimated sd: 1.3 #&gt; estimated skewness: 5.83 #&gt; estimated kurtosis: 61.6 For the data that include zeros (top row), the wood thrush shows an extremely zero-inflated and skewed distribution. There are a large number of zero-counts (checklists with no wood thrush detections). The Cullen &amp; Frey graph shows that the observed distribution of counts including zeros (the blue dot) is far from the normal, Poisson and negative binomial distributions. It is closest to the negative binomial distribution. For the counts only (bottom row), the wood thrush data still show a highly skewed distribution, with lots of checklists with low numbers and only a few checklists with &gt;5 woodthrush. The Cullen &amp; Frey graph indicates that even without zeros the data are far from complying with a standard distribution. These plots and conclusions are only indicative - they provide some information about what we can expect for distributions at the next step. Overall for wood thrush we can conclude that the counts are highly skewed with many zero observations. Prior to fitting our GAM models, let’s construct the model formula that we’ll use when we call the fitting function. As this is a GAM, for each variable, we’ll need to define the parameters of the smoothing function used. In particular, for each of the continuous covariates we’ll use a thin plate spline smooth with four degrees of freedom (k = 5). The degrees of freedom describe the maximum number of basis functions that contribute to the final smooth spline. In general across a variety of splines the degrees of freedom relate to the ‘wiggliness’ of the smooth function. Higher degrees of freedom will lead to a more wiggly and flexible function. The one variable with a different smooth is checklist start time, which is a cyclic variable (i.e. 0 and 24 are both midnight), so we’ll use a cubic cyclic spline (bs = &quot;cc&quot;) with six degrees of freedom (k = 7). The degrees of freedom selected define the maximum wiggliness and the gam function automatically reduces the degrees of freedom used if the data do not show evidence of a complex relationship. We recommend that users assess the fitted relationships to see whether they show biologically plausible relationships between variables and species counts. Splines can sometimes overfit, notably when sample sizes are very large, and in these cases it would be appropriate to reduce the degrees of freedom. GAMs are complex and powerful models, but assessing their fit and adapting them accordingly is sometimes more of an art than a science. We recommend people using these functions for their own models consult with a statistician or someone with experience in quantitative modelling. Let’s start by defining the model formula for the GAM. The following code builds the model formula programmatically, using only the covariates chosen in the previous section. Using this approach allows the formula to be correctly re-built if you decide to explore using a different set of covariates, for example, when modeling the abundance for a different species. # gam parameters # degrees of freedom for smoothing k &lt;- 5 # degrees of freedom for cyclic time of day smooth k_time &lt;- 7 # continuous predictors # hold out time to treat seperately since it&#39;s cyclic continuous_covs &lt;- ebird_split$train %&gt;% select(-observation_count, -protocol_type, -time_observations_started) %&gt;% names() # create model formula for predictors gam_formula_rhs &lt;- str_glue(&quot;s({var}, k = {k})&quot;, var = continuous_covs, k = k) %&gt;% str_flatten(collapse = &quot; + &quot;) %&gt;% str_glue(&quot; ~ &quot;, ., &quot; + protocol_type + &quot;, &quot;s(time_observations_started, bs = \\&quot;cc\\&quot;, k = {k})&quot;, k = k_time) %&gt;% as.formula() # model formula including response gam_formula &lt;- update.formula(observation_count ~ ., gam_formula_rhs) gam_formula #&gt; observation_count ~ s(day_of_year, k = 5) + s(duration_minutes, #&gt; k = 5) + s(effort_distance_km, k = 5) + s(number_observers, #&gt; k = 5) + s(checklist_calibration_index, k = 5) + s(pland_04, #&gt; k = 5) + s(pland_05, k = 5) + s(pland_12, k = 5) + s(pland_13, #&gt; k = 5) + protocol_type + s(time_observations_started, bs = &quot;cc&quot;, #&gt; k = 7) Alternatively, the formula can always be defined manually: observation_count ~ s(day_of_year, k = 5) + s(duration_minutes, k = 5) + s(effort_distance_km, k = 5) + s(number_observers, k = 5) + s(checklist_calibration_index, k = 5) + s(pland_04, k = 5) + s(pland_05, k = 5) + s(pland_12, k = 5) + s(pland_13, k = 5) + protocol_type + s(time_observations_started, bs = &quot;cc&quot;, k = 7) Now we’ll use this formula to fit GAM models, testing the following three distributions for the counts: Zero-inflated Poisson: This distribution effectively fits the data in two parts: (1) a binomial model that determines the variables associated with species presence and (2) a Poisson count model for those places with species presence, that determines the variables associated with species count. This is an effective distribution when there are a large number of zero counts in the data and the positive counts approximate a Poisson distribution. Negative binomial: The negative binomial distribution is related to the Poisson distribution. However, the Poisson distribution has the variance of the distribution equal to the mean. With the negative binomial the variance can be considerably different to the mean. This distribution is appropriate for over-dispersed data when the variance is much larger than the mean. This is a common pattern in ecological count data. Tweedie distribution: Tweedie provides the most flexibility as it encompasses a wide variety of distributions, including those with extremely high variance relative to the mean and extreme over-dispersion. The Tweedie is a general family of probability distributions which includes many more typical distributions: normal, gamma and Poisson. # explicitly specify where the knots should occur for time_observations_started # this ensures that the cyclic spline joins the variable at midnight # this won&#39;t happen by default if there are no data near midnight time_knots &lt;- list(time_observations_started = seq(0, 24, length.out = k_time)) # zero-inflated poisson m_ziplss &lt;- gam(list(gam_formula, # count model gam_formula_rhs), # presence model data = ebird_split$train, family = &quot;ziplss&quot;, knots = time_knots) # negative binomial m_nb &lt;- gam(gam_formula, data = ebird_split$train, family = &quot;nb&quot;, knots = time_knots) # tweedie distribution m_tw &lt;- gam(gam_formula, data = ebird_split$train, family = &quot;tw&quot;, knots = time_knots) 6.3.1 Assessment Before we use formal cross validation to assess these models, let’s visualize the results to see if they appear biologically feasible. Calling plot() on the fitted GAM objects produces plots of the smooth functions for each of the separate predictors, which gives us a sense of the effect of each predictor on the count response. Unfortunately, for large numbers of predictors, plot() will produce a cramped, unreadable plot. Instead, we write a function to capture the data behind the plotting function, then plot them using ggplot2 instead. # ggplot function plot_gam &lt;- function(m, title = NULL, ziplss = c(&quot;presence&quot;, &quot;abundance&quot;)) { # capture plot tmp &lt;- tempfile() png(tmp) p &lt;- plot(m, pages = 1) dev.off() unlink(tmp) # drop addition models in ziplss if (m$family$family == &quot;ziplss&quot;) { is_presence &lt;- map_lgl(p, ~ str_detect(.$ylab, &quot;^s\\\\.1&quot;)) if (ziplss == &quot;presence&quot;) { p &lt;- p[is_presence] } else { p &lt;- p[!is_presence] } } # extract data p_df &lt;- map_df(p, ~ tibble(cov = rep(.$xlab, length(.$x)), x = .$x, fit = .$fit, se = .$se)) # plot g &lt;- ggplot(p_df) + aes(x = x, y = fit, ymin = fit - se, ymax = fit + se) + geom_ribbon(fill = &quot;grey80&quot;) + geom_line(col = &quot;blue&quot;) + facet_wrap(~ cov, scales = &quot;free_x&quot;) + labs(x = NULL, y = &quot;Smooth function&quot;, title = title) print(g) invisible(p_df) } plot_gam(m_ziplss, title = &quot;Zero-inflated Poisson GAM (Presence Model)&quot;, ziplss = &quot;presence&quot;) plot_gam(m_ziplss, title = &quot;Zero-inflated Poisson GAM (Abundance Model)&quot;, ziplss = &quot;abundance&quot;) plot_gam(m_nb, title = &quot;Negative Binomial GAM&quot;) plot_gam(m_tw, title = &quot;Tweedie Distributed GAM&quot;) If these relationships seem too wiggly to be biologically realistic, you should reduce the degrees of freedom for the smooth until a biologically feasible relationship is achieved. In this case, the relationships appear to be reasonable. Next we’ll proceed with a formal cross-validation of the three models. Recall from Section 4.4.2 that this involves making predictions for the test dataset, which wasn’t used to fit the models, then assessing how well these predictions relate to the actual observed counts in the test dataset. Care needs to be taken when making predictions from the zero-inflated Poisson model since it has two components: the probability of presence and expected count given presence. As a result, the predict() function returns a two column matrix with the count and probability respectively, both on the scale of the link functions. So, we need to back-transform these values, then multiply them to get the predicted counts. obs_count &lt;- select(ebird_split$test, obs = observation_count) # presence probability is on the complimentary log-log scale # we can get the inverse link function with inv_link &lt;- binomial(link = &quot;cloglog&quot;)$linkinv # combine ziplss presence and count predictions m_ziplss_pred &lt;- predict(m_ziplss, ebird_split$test, type = &quot;link&quot;) %&gt;% as.data.frame() %&gt;% transmute(family = &quot;Zero-inflated Poisson&quot;, pred = inv_link(V2) * exp(V1)) %&gt;% bind_cols(obs_count) m_nb_pred &lt;- predict(m_nb, ebird_split$test, type = &quot;response&quot;) %&gt;% tibble(family = &quot;Negative Binomial&quot;, pred = .) %&gt;% bind_cols(obs_count) m_tw_pred &lt;- predict(m_tw, ebird_split$test, type = &quot;response&quot;) %&gt;% tibble(family = &quot;Tweedie&quot;, pred = .) %&gt;% bind_cols(obs_count) # combine predictions from all three models test_pred &lt;- bind_rows(m_ziplss_pred, m_nb_pred, m_tw_pred) %&gt;% mutate(family = as_factor(family)) Let’s look at a plot of how these predictions compare to the observed counts. Assessing the fit of the models depends considerably on the goals of the model and hence on the most important aspects of the model fit for the intended use. Here we assume that underestimated abundances are more problematic than overestimated abundances, but model fit assessment should be tailored to the particular goals of an estimated species distribution. We’ll highlight in red on these plots the regions where the predictions are underestimated by more than an order of magnitude. We’ll also overlay the line \\(y = x\\), which separates overestimates (above the line) from underestimates (below the line), and a blue smoothed fit showing the general trend through all the data. # plot predicted vs. observed ticks &lt;- c(0, 1, 10, 100, 1000) mx &lt;- round(max(test_pred$obs)) ggplot(test_pred) + aes(x = log10(obs + 1), y = log10(pred + 1)) + geom_jitter(alpha = 0.2, height = 0) + # y = x line geom_abline(slope = 1, intercept = 0, alpha = 0.5) + # area where counts off by a factor of 10 geom_area(data = tibble(x = log10(seq(0, mx - 1) + 1), y = log10(seq(0, mx - 1) / 10 + 1)), mapping = aes(x = x, y = y), fill = &quot;red&quot;, alpha = 0.2) + # loess fit geom_smooth(method = &quot;loess&quot;, method.args = list(span = 2 / 3, degree = 1)) + scale_x_continuous(breaks = log10(ticks + 1), labels = ticks) + scale_y_continuous(breaks = log10(ticks + 1), labels = ticks) + labs(x = &quot;Observed count&quot;, y = &quot;Predicted count&quot;) + facet_wrap(~ family, nrow = 1) We see that most of the observed counts are underestimated by the predictions, as most points and the blue line are below the gray \\(y = x\\) line. We also see that most of the checklists observe no wood thrush. Although most predictions for these are also zero (blue line is at 0), there are still a lot of places with predicted Wood Thrush where none were observed. There are also a large number of observations in that problematic region of underestimation by an order of magnitude or more. How many of these cases are there? test_pred %&gt;% group_by(family) %&gt;% summarize(n = sum(obs / pred &gt; 10), pct = mean(obs / pred &gt; 10)) #&gt; # A tibble: 3 x 3 #&gt; family n pct #&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Zero-inflated Poisson 131 0.0632 #&gt; 2 Negative Binomial 67 0.0323 #&gt; 3 Tweedie 70 0.0338 It appears based on this metric, that the zero-inflated Poisson model is performing worst in terms of underestimation. Let’s examine some of the cross-validation metrics: deviance explained, mean-squared error (MSE), and Spearman’s rank correlation. # deviance explained de &lt;- c(summary(m_ziplss)$dev.expl, summary(m_nb)$dev.expl, summary(m_tw)$dev.expl) # mse and rank correlation gam_assessment &lt;- test_pred %&gt;% group_by(family) %&gt;% summarise(mse = mean((obs - pred)^2, na.rm = TRUE), rank_cor = cor.test(obs, pred, method = &quot;spearman&quot;, exact = FALSE)$estimate) %&gt;% ungroup() %&gt;% mutate(dev_exp = de) family mse rank_cor dev_exp Zero-inflated Poisson 0.373 0.252 0.164 Negative Binomial 0.372 0.275 0.254 Tweedie 0.365 0.271 0.232 The zero-inflated Poisson model performs the worst across all metrics: it has the largest number of problematic errors, the highest MSE, and the lowest values for both rank correlation and deviance explained. The negative binomial and Tweedie models are more similar in performance. The negative binomial model has slightly more problematic errors and higher MSE, but it performs slightly better in terms of deviance explained and rank correlation. Either model could be chosen; however, it appears visually that predictions from the negative binomial model tend to be a bit higher, and closer to the \\(y = x\\) line, than predictions from the Tweedie model. So, taking a holistic view, the negative binomial model appears to be the best choice in this scenario. Depending on your focal species and region, as well as the particular goals of your analysis, some aspects of model fit will be more important than others, and you may find that a different model is most suitable for your situation. Overall, we see that none of these models has a high deviance explained. So a large degree of the variation in wood thrush counts on checklists are not explained by the variables in this model. It is important to hold this in mind when we use results from this model and produce predicted maps. In this case we select the negative binomial as the best model from these three options. pred_model &lt;- m_nb 6.4 Prediction Now that we’ve selected the negative binomial GAM, we can use this model to map Wood Thrush relative abundance in BCR 27! In Section 3.4, we created a prediction surface consisting of the PLAND habitat covariates summarized on a regular grid of points across BCR 27. In this section, we’ll make predictions of relative abundance at these points. However, first we need to bring effort variables into this prediction surface. We’ll use a standard eBird checklist: a 1 km, 1 hour traveling count done by a single observer expert eBirder (CCI = 2) at the peak time of day for detecting this this species. To determine this peak time, we’ll predict abundance and its 95% confidence limits at a series of times throughout the day, then pick the time at which the lower confidence limit is at its maximum. By using the lower confidence limits, we select a time that we are confident has high detectability and thus avoid potentially unrealistic predictions from times of day for which few or no data existed. # create a dataframe of covariates with a range of start times seq_tod &lt;- seq(0, 24, length.out = 300) tod_df &lt;- ebird_split$train %&gt;% # find average pland habitat covariates select(starts_with(&quot;pland&quot;)) %&gt;% summarize_all(mean, na.rm = TRUE) %&gt;% ungroup() %&gt;% # use standard checklist mutate(day_of_year = yday(ymd(&quot;2016-06-15&quot;)), duration_minutes = 60, effort_distance_km = 1, number_observers = 1, checklist_calibration_index = 2, protocol_type = &quot;Traveling&quot;) %&gt;% cbind(time_observations_started = seq_tod) # predict at different start times pred_tod &lt;- predict(pred_model, newdata = tod_df, type = &quot;link&quot;, se.fit = TRUE) %&gt;% as_tibble() %&gt;% # calculate backtransformed confidence limits transmute(time_observations_started = seq_tod, pred = pred_model$family$linkinv(fit), pred_lcl = pred_model$family$linkinv(fit - 1.96 * se.fit), pred_ucl = pred_model$family$linkinv(fit + 1.96 * se.fit)) # find optimal time of day t_peak &lt;- pred_tod$time_observations_started[which.max(pred_tod$pred_lcl)] # plot the partial dependence plot ggplot(pred_tod) + aes(x = time_observations_started, y = pred, ymin = pred_lcl, ymax = pred_ucl) + geom_ribbon(fill = &quot;grey80&quot;, alpha = 0.5) + geom_line() + geom_vline(xintercept = t_peak, color = &quot;blue&quot;, linetype = &quot;dashed&quot;) + labs(x = &quot;Hours since midnight&quot;, y = &quot;Predicted relative abundance&quot;, title = &quot;Effect of observation start time on Wood Thrush reporting&quot;, subtitle = &quot;Peak detectability shown as dashed blue line&quot;) So, the peak time of day for detecting Wood Thrush is around 4:15 AM. Let’s generate the prediction surface and make predictions at all the points. In addition to relative abundance, we’ll estimate standard error and 95% confidence limits. # add effort covariates to prediction surface pred_surface_eff &lt;- pred_surface %&gt;% mutate(day_of_year = yday(ymd(&quot;2017-06-15&quot;)), time_observations_started = t_peak, duration_minutes = 60, effort_distance_km = 1, number_observers = 1, checklist_calibration_index = 2, protocol_type = &quot;Traveling&quot;) # predict pred &lt;- predict(pred_model, newdata = pred_surface_eff, type = &quot;link&quot;, se.fit = TRUE) %&gt;% as_tibble() %&gt;% # calculate confidence limits and back transform transmute(abd = pred_model$family$linkinv(fit), abd_se = pred_model$family$linkinv(se.fit), abd_lcl = pred_model$family$linkinv(fit - 1.96 * se.fit), abd_ucl = pred_model$family$linkinv(fit + 1.96 * se.fit)) %&gt;% # add to prediction surface bind_cols(pred_surface_eff, .) %&gt;% select(latitude, longitude, abd, abd_se, abd_lcl, abd_ucl) Next, we’ll convert this data frame to spatial points using sf, then rasterize the points using the prediction surface raster template. r_pred &lt;- pred %&gt;% st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) %&gt;% select(abd, abd_se) %&gt;% st_transform(crs = projection(r)) %&gt;% rasterize(r) r_pred &lt;- r_pred[[-1]] # save the rasters writeRaster(r_pred[[&quot;abd&quot;]], filename = &quot;output/abundance-model_abundance_woothr.tif&quot;, overwrite = TRUE) writeRaster(r_pred[[&quot;abd_se&quot;]], filename = &quot;output/abundance-model_se_woothr.tif&quot;, overwrite = TRUE) Finally, let’s make a map! For the relative abundance map, we’ll treat very small values of relative abundance as zero. The values shown on this map are the expected number of Wood Thrush seen by an expert eBirder conducting a 1 hour, 1 km checklist for which counting started at about 4:15 AM. As detectability is not perfect, we expect true Wood Thrush abundance to be higher than these values, but without estimating detectability it is difficult to say how much higher. Also remember at this point that there was a lot of variation in eBird counts that were not explained by our covariates. So this map shows the best estimate of relative abundance, given the model and variables selected for modeling. # any expected abundances below this threshold are set to zero zero_threshold &lt;- 0.05 # project predictions r_pred_proj &lt;- projectRaster(r_pred, crs = map_proj$proj4string, method = &quot;ngb&quot;) par(mfrow = c(2, 1)) for (nm in names(r_pred)) { r_plot &lt;- r_pred_proj[[nm]] par(mar = c(3.5, 0.25, 0.25, 0.25)) # set up plot area plot(bcr, col = NA, border = NA) plot(ne_land, col = &quot;#dddddd&quot;, border = &quot;#888888&quot;, lwd = 0.5, add = TRUE) # modified plasma palette plasma_rev &lt;- rev(plasma(25, end = 0.9)) gray_int &lt;- colorRampPalette(c(&quot;#dddddd&quot;, plasma_rev[1])) pal &lt;- c(gray_int(4)[2], plasma_rev) # abundance vs. se if (nm == &quot;abd&quot;) { title &lt;- &quot;Wood Thrush Relative Abundance&quot; # set very low values to zero r_plot[r_plot &lt;= zero_threshold] &lt;- NA # log transform r_plot &lt;- log10(r_plot) # breaks and legend mx &lt;- ceiling(100 * cellStats(r_plot, max)) / 100 mn &lt;- floor(100 * cellStats(r_plot, min)) / 100 brks &lt;- seq(mn, mx, length.out = length(pal) + 1) lbl_brks &lt;- sort(c(-2:2, mn, mx)) lbls &lt;- round(10^lbl_brks, 2) } else { title &lt;- &quot;Wood Thrush Abundance Uncertainty (SE)&quot; # breaks and legend mx &lt;- ceiling(1000 * cellStats(r_plot, max)) / 1000 mn &lt;- floor(1000 * cellStats(r_plot, min)) / 1000 brks &lt;- seq(mn, mx, length.out = length(pal) + 1) lbl_brks &lt;- seq(mn, mx, length.out = 5) lbls &lt;- round(lbl_brks, 2) } # abundance plot(r_plot, col = pal, breaks = brks, maxpixels = ncell(r_plot), legend = FALSE, add = TRUE) # borders plot(bcr, border = &quot;#000000&quot;, col = NA, lwd = 1, add = TRUE) plot(ne_state_lines, col = &quot;#ffffff&quot;, lwd = 0.75, add = TRUE) plot(ne_country_lines, col = &quot;#ffffff&quot;, lwd = 1.5, add = TRUE) box() # legend par(new = TRUE, mar = c(0, 0, 0, 0)) image.plot(zlim = range(brks), legend.only = TRUE, col = pal, smallplot = c(0.25, 0.75, 0.06, 0.09), horizontal = TRUE, axis.args = list(at = lbl_brks, labels = lbls, fg = &quot;black&quot;, col.axis = &quot;black&quot;, cex.axis = 0.75, lwd.ticks = 0.5, padj = -1.5), legend.args = list(text = title, side = 3, col = &quot;black&quot;, cex = 1, line = 0)) } "],
["references.html", "References", " References "]
]
