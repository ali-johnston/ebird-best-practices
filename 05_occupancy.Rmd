---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Modeling Occupancy {#occupancy}

## Introduction {#occupancy-intro}

In this chapter, we'll cover the basic steps for estimating **occupancy probability** using data from eBird. In Chapter \@ref(encounter), we used analytical approaches that modeled variation in detectability by including covariates that are known to influence detection rates (e.g. effort). In contrast, occupancy models jointly model the ecological process of species occurrence *and* the observation process of species detection. The application of these models typically requires repeated visits to a single site during a relatively short time frame, over which the population can be considered closed. However, it is possible to *impose* this repeat visit structure on eBird data to generate a subset of data suitable for estimating occupancy. Here, we discuss how to process eBird observations to meet existing criteria for the application of occupancy models. To illustrate our example, we apply single-season occupancy models to estimate occupancy and detection probabilities of Wood Thrush for the month of June in BCR 27. 

This chapter is distinct from the previous chapter on modeling encounter rate in two important ways. First, the random forest model used in Chapter \@ref(encounter) is an example of a [machine learning](https://en.wikipedia.org/wiki/Machine_learning) approach, while the occupancy models used in this chapter are a more traditional likelihood approach. This latter type of statistical approach is best suited for addressing specific questions and hypotheses, while the goal of machine learning is primarily to identify patterns and make predictions [@bzdokPointsSignificanceStatistics2018]. Second, machine learning approaches can accommodate complex interactions between covariates and non-linear effects, often needed to model habitat associations that can vary across large spatial and temporal scales. In contrast, occupancy models are more suitable for exploring linear effects and simpler interactions. In this example, we specifically focus on the mechanics of filtering and formatting the data to fit occupancy models, and less on how to choose which predictors to include for detection and occupancy probabilities. The predictors we do include are informed by our inferences on variable from the random forest model in Chapter \@ref(encounter).

If you worked through the previous chapters, you should have all the data necessary for this chapter. You can also [download the data package](https://github.com/mstrimas/ebird-best-practices/raw/master/data/data.zip), and unzip it to your working directory.  Note that the Checklist Calibration Index (CCI), which calibrates observers and checklists against others from similar times and places, is an optional covariate in these models. Including CCI typical leads to marked improvement in model performance; however, due to the sensitive nature of these data you will need to [download them separately](https://ebird.org/data/download) after you agree to the terms and conditions. If you've downloaded these data, put the CCI text file in the `data/` subdirectory of your project.

```{r occupancy-data}
library(auk)
library(lubridate)
library(sf)
library(dggridR)
library(unmarked)
library(raster)
library(viridis)
library(MuMIn)
library(AICcmodavg)
library(fields)
library(tidyverse)
# resolve namespace conflicts
select <- dplyr::select
projection <- raster::projection

set.seed(1)

# ebird data
ebird <- read_csv("data/ebd_woothr_june_bcr27_zf.csv") %>% 
  mutate(year = year(observation_date),
         # occupancy modeling requires an integer response
         species_observed = as.integer(species_observed))

# modis habitat covariates
habitat <- read_csv("data/modis_pland_location-year.csv") %>% 
  mutate(year = as.integer(year))

# combine ebird and habitat data
ebird_habitat <- inner_join(ebird, habitat, by = c("locality_id", "year"))

# optional checklist calibration index
cci_file <- "data/cci_june_bcr27.csv"
if (file.exists(cci_file)) {
  cci <- read_csv("data/cci_june_bcr27.csv")
  ebird_habitat <- inner_join(ebird_habitat, cci, by = "checklist_id") %>% 
    filter(!is.na(checklist_calibration_index))
}

# prediction surface
pred_surface <- read_csv("data/modis_pland_prediction-surface.csv")
r <- raster("data/prediction-surface.tif")

# load gis data for making maps
map_proj <- st_crs(102003)
ne_land <- read_sf("data/gis-data.gpkg", "ne_land") %>% 
  st_transform(crs = map_proj) %>% 
  st_geometry()
bcr <- read_sf("data/gis-data.gpkg", "bcr") %>% 
  st_transform(crs = map_proj) %>% 
  st_geometry()
ne_country_lines <- read_sf("data/gis-data.gpkg", "ne_country_lines") %>% 
  st_transform(crs = map_proj) %>% 
  st_geometry()
ne_state_lines <- read_sf("data/gis-data.gpkg", "ne_state_lines") %>% 
  st_transform(crs = map_proj) %>% 
  st_geometry()
```

## Data preparation {#occupancy-data}

First, we need to extract a subset of the eBird data suitable for occupancy modeling, then perform spatiotemporal subsampling to deal with bias in the data. Let's start by filtering our data to include only checklists with 5 or fewer observers, since there are very few observations with more than 5 observers.

```{r occupancy-data-obs}
ebird_filtered <- filter(ebird_habitat, number_observers <= 5)
```

In some situations, you may want to further filter the data based on the results of an exploratory analysis similar to the one conducted in Section \@ref(ebird-explore). However, for the purpose of comparing results among different modeling approaches and best practices, we won't further filter the observations in eBird for our occupancy example.

### Extracting occupancy data {#occupancy-data-sites}

From the eBird data, we can generate detection histories for each location we define as a site. In this example, we define the month of June as the time period over which we assume that the population is closed for Wood Thrush, and a site is defined as a location (`locality_id` in the data) that is visited at least twice by the same observer within our defined period of closure (i.e. the month of June).

The `auk` function `filter_repeat_visits()` is designed to extract a subset of eBird data suitable for occupancy modeling. We first filter the data to only sites that have at least two visits (`min_obs = 2`), then define the maximum length of our detection history as 10 visits or checklists (`max_obs = 10`). When a specific site has been visited more than 10 times, the function will randomly select 10 checklists from the total number of visits. Since we only have data from June, using `annual_closure = TRUE` defines the temporal period of closure as the whole month of June for a given primary sampling period (i.e. year). Finally, `site_vars` specifies the set of variables that defines a site. In this example, a site is defined jointly by location and observer IDs.

```{r occupancy-data-sites-repeat}
occ <- filter_repeat_visits(ebird_filtered %>% mutate_at(c("latitude", "longitude"), ~ round(., 4)), 
                            min_obs = 2, max_obs = 10,
                            annual_closure = TRUE,
                            date_var = "observation_date",
                            site_vars = c("locality_id", "observer_id"))
# entire data set
nrow(ebird_habitat)
# reduced data set
nrow(occ)
# how many individual sites there are
n_distinct(occ$site)
```

Three new variables are added to the dataset by `filter_repeat_visits()`: `site` is a unique site ID, `closure_id` identifies the primary period of closure (in this case the year), and `n_observations` is the number of visits to each site. Our data is now formatted and ready to be analyzed using occupancy models. Note that we've made a tradeoff in sample size, dropping from `r scales::comma(nrow(ebird_filtered))` checklists to `r scales::comma(nrow(occ))` checklists over `r scales::comma(n_distinct(occ$site))` sites.

We'll fit single-season occupancy models using the `unmarked` R package. For further details on the type of data format required for this package, consult the documentation for the `unmarked` function `formatWide()`. The `auk` function `format_unmarked_occu()` converts data from a vertical format in which each row is an observation (as in the EBD) to a horizontal detection history required by `unmarked`, where each row is a site. At this stage, we need to specify which variables will be site-level covariates and which will be observation-level covariates. Covariates for each site (`site_covs`) are specific to each primary sampling period of closure (month of June in this case), and will influence the ecological process of species occurrence. Covariates collected during each sampling occasion (`obs_covs`) are those that are specific to that sampling occasion (i.e. checklist) and will influence the observational process, or detection probability.

For this example, we'll use MODIS habitat variables as covariates for modeling the occupancy probability of Wood Thrush. Based on [predictor importance](#encounter-habitat-pi) measures from Chapter \@ref(encounter), we include deciduous broadleaf forest (`pland_04`) and mixed forest (`pland_05`) as habitat types for which we expect positive relationships with occupancy, and croplands (`pland_12`) and urban (`pland_13`), for which we expect negative relationships. 

For detection probability, we include the six effort variables, since they are related to the detection process. In addition, habitat is known to affect detectability, and many species are harder to detect in densely forested habitatsâ€”the same habitats preferred by Wood Thrush. Occupancy models allow us to tease apart the differing effects of habitat on detection and occupancy. With this in mind, we'll include deciduous broadleaf forest (`pland_04`) and mixed forest (`pland_05`) as additional detection covariates.

```{r occupancy-data-sites-wide}
# if cci is available, use it as an observation covariate
obs_covs <- c("time_observations_started", 
              "duration_minutes", 
              "effort_distance_km", 
              "number_observers", 
              "protocol_type",
              "pland_04", 
              "pland_05")
if ("checklist_calibration_index" %in% names(occ)) {
  obs_covs <- c(obs_covs, "checklist_calibration_index")
}

# format for unmarked
occ_wide <- format_unmarked_occu(occ, 
                                 site_id = "site", 
                                 response = "species_observed",
                                 site_covs = c("n_observations", 
                                               "latitude", "longitude", 
                                               # % deciduous forest
                                               "pland_04", 
                                               # % mixed forest
                                               "pland_05",
                                               # % cropland
                                               "pland_12",
                                               # % urban
                                               "pland_13"),
                                 obs_covs = obs_covs)
```

### Spatial subsampling {#encounter-data-sss}

As discussed in Section \@ref(encounter-sss), spatial subsampling of eBird observations reduces spatial bias. We'll use the same hexagonal subsampling approach as in Chapter \@ref(encounter); however, here we'll subsample at the level of sites rather than observations.

```{r encounter-data-sss, results = "hide"}
# generate hexagonal grid with ~ 5 km betweeen cells
dggs <- dgconstruct(spacing = 5)
# get hexagonal cell id for each site
occ_wide_cell <- occ_wide %>% 
  mutate(cell = dgGEO_to_SEQNUM(dggs, longitude, latitude)$seqnum)
# sample one checklist per grid cell
occ_ss <- occ_wide_cell %>% 
  group_by(cell) %>% 
  sample_n(size = 1) %>% 
  ungroup() %>% 
  select(-cell)
```

This resulted in a `r scales::percent(1 - nrow(occ_ss) / nrow(occ_wide))` decrease in the number of sites.

### `unmarked` object {#encounter-data-unmarked}

Finally, we'll convert this dataframe of observations into an `unmarked` object, which is required for fitting occupancy models.

```{r encounter-data-unmarked}
occ_um <- formatWide(occ_ss, type = "unmarkedFrameOccu")
summary(occ_um)
```

## Occupancy modeling {#occupancy-model}

Now that we've created a data frame with detection histories and covariates, we can use `unmarked` to fit a single-season occupancy model. In this book, we won't delve into the mechanics of occupacy models; however, there is a rich literature on occupancy modeling and readers wishing to learn more about this field may want to consult the book on the topic by MacKenzie et al. [-@mackenzieOccupancyEstimationModeling2017]. Here we simply fit a single-season occupancy model to our data using the `occu()` function, specifying the detection and occupancy covariates, respectively, via a double right-hand sided formula of the form `~ detection covariates ~ occupancy covariates`.

```{r occupancy-model-fit}
# use cci in model formula if available
if ("checklist_calibration_index" %in% names(occ_um@obsCovs)) {
  mod_formula <- ~ time_observations_started + 
                    duration_minutes + 
                    effort_distance_km + 
                    number_observers + 
                    protocol_type +
                    checklist_calibration_index +
                    pland_04 + pland_05 ~ 
                  pland_04 + pland_05 + pland_12 + pland_13
} else {
    mod_formula <- ~ time_observations_started + 
                    duration_minutes + 
                    effort_distance_km + 
                    number_observers + 
                    protocol_type +
                    pland_04 + pland_05 ~
                  pland_04 + pland_05 + pland_12 + pland_13
}

# fit model
occ_model <- occu(mod_formula, data = occ_um)
# look at the regression coefficients from the models
summary(occ_model)
```

### Assessment {#occupancy-model-assess}

Occupancy models assume that at at least one model in the set provides an adequate fit to the data. Although few goodness-of-fit tests exist for occupancy models, we'll demonstrate how to perform the MacKenzie and Bailey [-@mackenzieAssessingFitSiteoccupancy2004] goodness-of-fit test.  This approach calculates a Pearson's chi-square fit statistic from the observed and expected frequencies of detection histories for a given model. For this example, we'll use the `mb.gof.test()` test function in the `AICcmodavg` package, which can handle occupancy models produced by the `occu()` function in `unmarked`, to calculate the observed and expected frequencies of detection histories. Note that this process requires simulating a large number of bootstrap samples (1,000 here) and therefore takes a long time to run. You may want to skip this section or reduce `nsim` to a much smaller number (e.g. 10) in the interest of speed. However, when applying this in practice, you should run the test with the full number of simulations to get accurate results.

```{r occupancy-model-assess, eval = FALSE, echo = 1:2}
occ_gof <- mb.gof.test(occ_model, nsim = 1000, plot.hist = FALSE)
print(occ_gof)
saveRDS(occ_gof, "output/woothr_occupancy-model_gof.rds")
```

```{r occupancy-model-assess-actual, echo = FALSE}
# read in saved gof test results 
occ_gof <- readRDS("output/woothr_occupancy-model_gof.rds")
# print chisq table
gof <- occ_gof
gof$chisq.table <- NULL
print(gof)
```

For this example, the probability of getting the calculated chi-square statistic under a null sampling distribution is indicated by the p-value of `r gof$p.value`, indicating that there is no reason to consider a lack of fit (p > 0.1). In addition, we also get an estimate of the overdisperson parameter (c-hat) for the model by dividing the observed chi-square statistic by the mean of the statistics obtained from simulation. In this example, c-hat = `r round(gof$c.hat.est, 2)`, which is very close to c-hat = 1, indicating that the variance is not greater than the mean, and that there is no evidence for overdispersion. 

### Model selection {#occupancy-model-select}

Next, we use a model selection approach to compare and rank our candidate model set. For this example, we use the `dredge()` function to explore a candidate set consisting of all possible additive combinations of the global model. However, we suggest that a more thoughtful approach be considered for specific applications and different types of predictor variables.

```{r occupancy-model-select-dredge-occ, echo = FALSE}
det_terms <- getAllTerms(occ_model) %>% 
  keep(str_detect, pattern = "^p\\(")
occ_dredge <- dredge(occ_model, fixed = det_terms)
```

```{r occupancy-model-select-dredge, eval = FALSE}
# dredge candidate model set
occ_dredge <- dredge(occ_model)

# model comparison
select(occ_dredge, df, logLik, AICc, delta, weight)
```

```{r occupancy-model-select-dredge-compare, echo = FALSE}
# model comparison
select(occ_dredge, df, logLik, AICc, delta, weight)
```

A quick look at the dredge object reveals that there is not a clear model, or even set of models, that are most likely to have generated our data. This is evident from the low AIC weight for the model with the lowest AICc value. Given this, and the fact that all of our effects are linear and use the same family and link function, we'll average across all models, weighted by AICc, to produce a final model that we'll use for prediction. However, there may be scenarios in which there is a clear set of high performing models, in which case you can use the `get.models()` function to extract just these models prior to averaging.

```{r occupancy-model-select-average}
# average models based on model weights 
occ_avg <- model.avg(occ_dredge, fit = TRUE)

# model coefficients
t(occ_avg$coefficients)
```

## Prediction {#occupancy-predict}

In this section, we'll estimate the distribution of Wood Thrush in BCR 27. Similar to Section \@ref(habitat-prediction), we'll generate a prediction surface using the PLAND habitat covariates summarized on a regular grid of points across BCR 27. For this, we'll use the `predict()` function to estimate occupancy probabilities, standard errors, and confidence intervals. 

Recall that when we [predicted encouter rate](#encounter-predict), we had to include effort variables in our prediction surface. We don't need to do that here because the occupancy submodel doesn't depend on the effort covariates, these only occur in the detection submodel.

```{r occupancy-predict-predict, eval = FALSE, results = "hold", echo = 1:9}
occ_pred <- predict(occ_avg, 
                    newdata = as.data.frame(pred_surface), 
                    type = "state")

# add to prediction surface
pred_occ <- bind_cols(pred_surface, 
                      occ_prob = occ_pred$fit, 
                      occ_se = occ_pred$se.fit) %>% 
  select(latitude, longitude, occ_prob, occ_se)
saveRDS(pred_occ, "output/woothr_occupancy-model_predictions.rds")
```

```{r occupancy-predict-predict-load, echo = FALSE}
pred_occ <- readRDS("output/woothr_occupancy-model_predictions.rds")
```

Next, we'll convert this data frame to spatial feaatures using `sf`, then rasterize the points using the prediction surface raster template.

```{r occupancy-predict-rasterize}
r_pred <- pred_occ %>% 
  # convert to spatial features
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>% 
  st_transform(crs = projection(r)) %>% 
  # rasterize
  rasterize(r)
r_pred <- r_pred[[c("occ_prob", "occ_se")]]

# save the raster
tif_dir <- "output"
if (!dir.exists(tif_dir)) {
  dir.create(tif_dir)
}
writeRaster(r_pred[["occ_prob"]], 
            filename = file.path(tif_dir, "occupancy-model_prob_woothr.tif"),
            overwrite = TRUE)
writeRaster(r_pred[["occ_se"]], 
            filename = file.path(tif_dir, "occupancy-model_se_woothr.tif"), 
            overwrite = TRUE)
```

Finally, we can map these predictions!

```{r occupancy-predict-map, fig.asp = 1.236}
# project predictions
r_pred_proj <- projectRaster(r_pred, crs = map_proj$proj4string, method = "ngb")

par(mfrow = c(2, 1))
for (nm in names(r_pred)) {
  r_plot <- r_pred_proj[[nm]]
  
  par(mar = c(3.5, 0.25, 0.25, 0.25))
  # set up plot area
  plot(bcr, col = NA, border = NA)
  plot(ne_land, col = "#dddddd", border = "#888888", lwd = 0.5, add = TRUE)
  
  # modified plasma palette
  plasma_rev <- rev(plasma(25, end = 0.9))
  gray_int <- colorRampPalette(c("#dddddd", plasma_rev[1]))
  pal <- c(gray_int(4)[2], plasma_rev)
  
  # occupancy
  mx <- ceiling(1000 * cellStats(r_plot, max)) / 1000
  brks <- seq(0, mx, length.out = length(pal) + 1)
  plot(r_plot, 
       col = pal, breaks = brks, 
       maxpixels = ncell(r_plot),
       legend = FALSE, add = TRUE)
  
  # borders
  plot(bcr, border = "#000000", col = NA, lwd = 1, add = TRUE)
  plot(ne_state_lines, col = "#ffffff", lwd = 0.75, add = TRUE)
  plot(ne_country_lines, col = "#ffffff", lwd = 1.5, add = TRUE)
  box()
  
  # legend
  par(new = TRUE, mar = c(0, 0, 0, 0))
  if (nm == "occ_prob") {
    title <- "Wood Thrush Occupancy Probability"
    lbl_brks <- seq(0, mx, by = 0.1)
  } else {
    lbl_brks <- seq(0, mx, by = 0.02)
    title <- "Wood Thrush Occupancy Uncertainty (SE)"
  }
  
  image.plot(zlim = range(brks), legend.only = TRUE, col = pal,
             smallplot = c(0.25, 0.75, 0.06, 0.09),
             horizontal = TRUE,
             axis.args = list(at = lbl_brks, labels = lbl_brks,
                              fg = "black", col.axis = "black",
                              cex.axis = 0.75, lwd.ticks = 0.5,
                              padj = -1.5),
             legend.args = list(text = title,
                                side = 3, col = "black",
                                cex = 1, line = 0))
}
```
